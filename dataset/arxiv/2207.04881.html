<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2207.04881] Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario</title><meta property="og:description" content="Spiking neural networks (SNNs) are largely inspired by biology and neuroscience and leverage ideas and theories to create fast and efficient learning systems. Spiking neuron models are adopted as core processing units …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2207.04881">

<!--Generated on Thu Dec 22 21:50:40 2022 by LaTeXML (version 0.8.6) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.5.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.0.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Davide Liberato Manna, Alex Vicente Sola,
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_bold">Paul Kirkland, Gaetano Di Caterina</span> 
<br class="ltx_break">Neuromorphic Sensor Signal Processing Lab
<br class="ltx_break">Centre for Image and Signal Processing
<br class="ltx_break">Electrical and Electronic Engineering
<br class="ltx_break">University of Strathclyde
<br class="ltx_break">Glasgow, United Kingdom. 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">email: davide.manna@strath.ac.uk</span>
&amp;Trevor Bihl
<br class="ltx_break">Air Force Research Laboratory
<br class="ltx_break">Wright Patterson AFB, OH
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Spiking neural networks (SNNs) are largely inspired by biology and neuroscience and leverage ideas and theories to create fast and efficient learning systems. Spiking neuron models are adopted as core processing units in neuromorphic systems because they enable event-based processing. Among many neuron models, the integrate-and-fire (I&amp;F) models are often adopted, with the simple Leaky I&amp;F (LIF) being the most used. The reason for adopting such models is their efficiency and/or biological plausibility.
Nevertheless, rigorous justification for adopting LIF over other neuron models for use in artificial learning systems has not yet been studied. This work considers various neuron models in the literature and then selects computational neuron models that are single-variable, efficient, and display different types of complexities. From this selection, we make a comparative study of three simple I&amp;F neuron models, namely the LIF, the Quadratic I&amp;F (QIF) and the Exponential I&amp;F (EIF), to understand whether the use of more complex models increases the performance of the system and whether the choice of a neuron model can be directed by the task to be completed.
Neuron models are tested within an SNN trained with Spike-Timing Dependent Plasticity (STDP) on a classification task on the N-MNIST and DVS Gestures datasets. Experimental results reveal that more complex neurons manifest the same ability as simpler ones to achieve high levels of accuracy on a simple dataset (N-MNIST), albeit requiring comparably more hyper-parameter tuning. However, when the data possess richer Spatio-temporal features, the QIF and EIF neuron models steadily achieve better results. This suggests that accurately selecting the model based on the richness of the feature spectrum of the data could improve the whole system’s performance. Finally, the code implementing the spiking neurons in the SpykeTorch framework is made publicly available.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_italic">Spiking Neural Networks, STDP, Unsupervised Learning, Spiking Neurons, Temporal Features</span>
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">As technology in the Neuromorphic (NM) computing field keeps on advancing, so are the software methodologies and algorithms that can leverage the low-power, low-latency and event-driven properties that characterize NM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Often, inspired by the success of conventional deep learning, this results in the development of Spiking Neural Networks (SNNs).
When it comes to designing an SNN learning system for some machine learning task, researchers are faced with many decisions to make. Among these comes the choice of a particular neuron model. This specific aspect of the development of an SNN is a very sensitive one as spiking neurons are the core processing units of an NM system. To draw a parallel with the conventional Deep Learning (DL) research, spiking neurons can be thought of as being activation functions (such as the ReLU, ATAN etc), but holding an internal state. The dynamics of this state through time are governed by the differential equations that constitute the spiking neuron model.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Different neuron models exhibit different state dynamics. From a neuroscience point of view, these differences are very clear <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Some models are able to capture certain intrinsic behaviours of neurons, e.g. they can burst, chatter or fast-spike, while others cannot. Some models are also better at approximating subthreshold dynamics, thus possibly being more accurate representations of real neurons.
However, it is still unclear how this ability translates into applicability in SNNs. There is in fact no definite answer onto whether certain types of neural dynamics can be beneficial to particular SNN applications, nor any common knowledge on the criteria that should drive the choice of such neurons in relation to such dynamics.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Within some specific contexts, the choice is constrained by the available hardware. As a matter of fact, several neuromorphic chips allow to only adopt the specific neuron model that the chip is able to emulate. BrainScaleS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> for instance allows to only adopt the Adaptive Exponential Integrate-and-Fire neuron model; NeuroGrid <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> allows only an Adaptive Quadratic Integrate-and-Fire model ; meanwhile, Loihi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, SyNAPSE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and TrueNorth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> allow only Leaky Integrate-and-Fire (LIF) based models.
Until recently, the only chip allowing the implementation of any type of neuron model was SpiNNaker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. However, the recently released Loihi 2 adds to the list of chips with programmable neuron models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, hence highlighting the importance of an accurate investigation on this matter.
</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">It is thus interesting to look at what are the most suitable neurons models for SNN development. This can help to understand if the dynamics of the neurons relate, in some way, to the dynamics of the spatio-temporal features of the data.

<br class="ltx_break">
<br class="ltx_break">Simple LIF neurons are the de-facto standard choice when it comes to SNN design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. When a rationale for this is provided, this choice is often attributed to the simplicity and, consequently, to the efficiency of the LIF neuron model. Whatever the case, such reasons hardly account for the accuracy performance of the task at hand, neither for the temporal feature representation capability of the model. Other works rely on more complex neuron models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, attributing the choice to the biological plausibility or, once again, to efficiency.
Neurons with different dynamics are present in areas of the brain with different functionalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>; however, the same does not apply to spiking neuron models in ML, where often the simplest neurons are used, leaving it unclear whether there are advantages or disadvantages relative to different types of NM data.

<br class="ltx_break">
<br class="ltx_break">This work aims to answer the following research questions:
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Does the chosen neuron model influence the performance of an SNN?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i2.p1.1" class="ltx_p">Should the choice of the neuron model be related with the data it will have to process?</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">Specifically, we are interested in understanding whether neuron models with different and more complex neuronal dynamics display any advantages over simpler (LIF) ones in an unsupervised learning context. Furthermore, we investigate whether such differences might exist depending on the task set to the network; hence we perform experiments using two different datasets. To do this, we first develop a basic experiment, which represents a simple yet efficient way to start a comparison between neuron models. We select neuron models so that they scale up in terms of complexity and spiking patterns, and evaluate their performance within the same neural network architectures on the N-MNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Then, we use the same neural network and train it on classification tasks taken from the DVS Gestures dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, which displays a richer distribution of events.
In order to perform the aforementioned experiments, we further contribute by enriching the SpykeTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> framework with a new set of spiking neurons<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code available at https://www.github.com/daevem/SpykeTorch-Extended</span></span></span>.


<br class="ltx_break">
<br class="ltx_break">The rest of this paper is organized as follows: in Section 2 we provide some background information regarding the multitude of neuron models found in the literature and highlight some relevant related works; in Section 3 we present our experimentation pipeline in detail, focusing on the datasets, neural network design and learning paradigms; Sections 4 and 5 contain respectively the results obtained through our experiments and initiate an in-depth discussion on such results; Section 6 concludes the paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 2 </span>Background and Related Works</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Spiking neuron models were first born in the field of neuroscience and neurophysiology, where mathematical models were developed to reproduce what was found by recording the activity of real neurons <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Early spiking neural networks resulted from studies aimed at understanding biological dynamics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, or simulating areas of the brain and neuronal interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. The shift towards their use for computational tasks was gradual and was formalised afterwards <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, with the focus generally being on the overall computational abilities of the network.
When it comes to developing SNNs for ML applications, spiking neurons can be thought of as stateful activation functions. This means they retain a state of their value (the membrane potential) reached through previous inputs. They are thresholding functions, therefore allowing to only forward information upon the reaching of a set threshold
.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">In conventional DL, activation functions have been extensively studied due to their importance in the propagation of the information. Nonlinear functions such as the sigmoid and Tanh were introduced to break the linearity of multilayer Perceptrons <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Rectified Linear Units (ReLUs) substituted them to solve the vanishing gradient problem and allow deeper networks. Further variants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> addressed other issues like the dying ReLU problem and helped to improve the performance of the networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.
Instead, in the context of SNNs and spiking neurons, it is hard to find works in the literature relative to the differences in the use of different neuron models in SNNs for NM and DL applications. To the best of our knowledge, the only work considering the role of spiking neurons in learning from a DL point of view is the one by Traub et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>; however, they focus on the qualitative properties of Spike-Timing-Dependent Plasticity (STDP) and the mean firing rate of the system after training. Furthermore, they consider a non-NM dataset and a different set of neurons.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">Most of the works on spiking neurons concentrate on the neurobiological aspects they expose. One of the most influential works in this matter is the one by Izhikevich <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, which compared several models of spiking neurons (LIF, LIF with adaptation, LIF-or-burst, resonate-and-fire, QIF, Izhikevich’s, FitzHugh-Nagumo, Hindmarsh-Rose, Morris-Lecar, Wilson, Hodgkin-Huxley), outlining their ability to reproduce observed neuronal behaviours and the cost (in terms of floating-point operations) of implementing such neurons in software applications. Similar work was conducted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, but focusing on a smaller subset of neurons (LIF, Izhikevich’s, FitzHugh-Nagumo, Wilson, Hodgkin-Huxley) and analysing their numerical stability.
Although they closely study spiking neuron models, the two studies above concentrate on their computational costs and the intrinsic biological mechanics that each model can reproduce. However, they do not consider the effect of using spiking neurons with different dynamics in a DL system.

<br class="ltx_break">A number of other works concentrate on the efficacy of neuron models in representing observed cortical neurons firing patterns. One example is given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, where the authors make an exploratory analysis of how parameters influence Izhikevich’s neurons in showing different spiking patters. Still regarding Izhikevich’s neurons, Kumar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> estimate parameters that allow the neuron model to optimally reproduce a given spike train. Teeter et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> use a generalized version of the LIF neuron model (GLIF) to understand whether more complex models allow to predict spike timing behaviors more closely; they conclude that this ability does not increase monotonically with the complexity, nor with the ability to reproduce sub-threshold dynamics. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> it is argued that integrate-and-fire (I&amp;F) neuron models are good enough estimators of input spike trains when coupled with an adaptation variable. This is both quantitatively and qualitatively shown by the authors and provides a good ground to the adoption of this family of neuron models.
<br class="ltx_break">Finally, neuron models in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> are compared within a retina-like neural network modelled with a liquid state machine (LSM). The performance of each neuron here is measured in terms of the "separation ability", i.e. the ability of the LSM to generate different responses to different stimuli. They find that all the models achieved reasonable separation ability, with the exception of Izhikevich’s model.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2207.04881/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="609" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Venn Diagram of Some Spiking Neurons.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Neuron Models in the Literature</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p">The neuroscience literature is full of different neuron models, mostly describing the dynamics of the soma (core) of the cortical neurons. These can be roughly subdivided into two larger groups (see Figure <a href="#S2.F1" title="Figure 1 ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), the bio-physical or conductance-based models and the event-based or integrate-and-fire models.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Conductance-based Models</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">This class of neuron models is characterized by the fact that all the variables and parameters present in the model have a biophysical correspondence and are therefore measurable through experiments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. Among them, the Hodgkin-Huxley (HH) model is considered to be one of the most important in computational neuroscience and defines a system of 4 non-linear differential equation with four variables and a number of parameters. While further levels of complexity can be attained by including further variables in the model, this is not amenable to mathematical analysis. In fact, other simpler conductance-based models have been derived in the literature in order to ease the analysis, while still retaining biophysical plausibility. Some examples are the FitzHugh-Nagumo model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, the Hindmarsh-Rose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> and the Morris-Lecar model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. Nevertheless, they still remain rather complex for what concerns analysis and computation, therefore this family of neuron models is often used only when studying single-cell or small population dynamics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Phenomenological Models</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS2.p1.6" class="ltx_p">The family of Integrate-and-Fire or phenomenological neuron models comprises all those models that treat spikes as stereotypical events in time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Therefore, each spike is completely described by the time at which it occurred, or was emitted. Integrate-and-fire models require at least two equations, one describing the dynamics of the membrane potential and the other one defining the action potential generation. Events are integrated over time and convey electrical charges that can cause excitation or inhibition of the membrane potential of the receiving neuron.
Differently from the conductance-based models, the phenomenological ones are more indicated for the development of neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, thanks to their overall lower complexity and the lower number of parameters, which enable easier fitting. 
<br class="ltx_break">
<br class="ltx_break">The simplest model, apart from the perfect integrator, is the LIF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. The dynamics of the membrane potential are here described by the following linear differential equation:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\tau_{m}\frac{du}{dt}=-(u(t)-u_{rest})+R\cdot I" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml"><msub id="S2.E1.m1.2.2.3.2" xref="S2.E1.m1.2.2.3.2.cmml"><mi id="S2.E1.m1.2.2.3.2.2" xref="S2.E1.m1.2.2.3.2.2.cmml">τ</mi><mi id="S2.E1.m1.2.2.3.2.3" xref="S2.E1.m1.2.2.3.2.3.cmml">m</mi></msub><mo id="S2.E1.m1.2.2.3.1" xref="S2.E1.m1.2.2.3.1.cmml">⁢</mo><mfrac id="S2.E1.m1.2.2.3.3" xref="S2.E1.m1.2.2.3.3.cmml"><mrow id="S2.E1.m1.2.2.3.3.2" xref="S2.E1.m1.2.2.3.3.2.cmml"><mi id="S2.E1.m1.2.2.3.3.2.2" xref="S2.E1.m1.2.2.3.3.2.2.cmml">d</mi><mo id="S2.E1.m1.2.2.3.3.2.1" xref="S2.E1.m1.2.2.3.3.2.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.3.3.2.3" xref="S2.E1.m1.2.2.3.3.2.3.cmml">u</mi></mrow><mrow id="S2.E1.m1.2.2.3.3.3" xref="S2.E1.m1.2.2.3.3.3.cmml"><mi id="S2.E1.m1.2.2.3.3.3.2" xref="S2.E1.m1.2.2.3.3.3.2.cmml">d</mi><mo id="S2.E1.m1.2.2.3.3.3.1" xref="S2.E1.m1.2.2.3.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.3.3.3.3" xref="S2.E1.m1.2.2.3.3.3.3.cmml">t</mi></mrow></mfrac></mrow><mo id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mo id="S2.E1.m1.2.2.1.1a" xref="S2.E1.m1.2.2.1.1.cmml">−</mo><mrow id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.2.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2.cmml">u</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.2.1" xref="S2.E1.m1.2.2.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.2.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.2.3.2.1" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.2.3.2.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">−</mo><msub id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.3.2.cmml">u</mi><mrow id="S2.E1.m1.2.2.1.1.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml">r</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.3.3.1" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.1.1.1.1.1.3.3.3" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml">e</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.3.3.1a" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.1.1.1.1.1.3.3.4" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.4.cmml">s</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.3.3.1b" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E1.m1.2.2.1.1.1.1.1.3.3.5" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.5.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.2.cmml">+</mo><mrow id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.2.2.1.3.cmml"><mi id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.2.2.1.3.2.cmml">R</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.1.3.1" xref="S2.E1.m1.2.2.1.3.1.cmml">⋅</mo><mi id="S2.E1.m1.2.2.1.3.3" xref="S2.E1.m1.2.2.1.3.3.cmml">I</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"></eq><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"><times id="S2.E1.m1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.3.1"></times><apply id="S2.E1.m1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3.2.1.cmml" xref="S2.E1.m1.2.2.3.2">subscript</csymbol><ci id="S2.E1.m1.2.2.3.2.2.cmml" xref="S2.E1.m1.2.2.3.2.2">𝜏</ci><ci id="S2.E1.m1.2.2.3.2.3.cmml" xref="S2.E1.m1.2.2.3.2.3">𝑚</ci></apply><apply id="S2.E1.m1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.3.3"><divide id="S2.E1.m1.2.2.3.3.1.cmml" xref="S2.E1.m1.2.2.3.3"></divide><apply id="S2.E1.m1.2.2.3.3.2.cmml" xref="S2.E1.m1.2.2.3.3.2"><times id="S2.E1.m1.2.2.3.3.2.1.cmml" xref="S2.E1.m1.2.2.3.3.2.1"></times><ci id="S2.E1.m1.2.2.3.3.2.2.cmml" xref="S2.E1.m1.2.2.3.3.2.2">𝑑</ci><ci id="S2.E1.m1.2.2.3.3.2.3.cmml" xref="S2.E1.m1.2.2.3.3.2.3">𝑢</ci></apply><apply id="S2.E1.m1.2.2.3.3.3.cmml" xref="S2.E1.m1.2.2.3.3.3"><times id="S2.E1.m1.2.2.3.3.3.1.cmml" xref="S2.E1.m1.2.2.3.3.3.1"></times><ci id="S2.E1.m1.2.2.3.3.3.2.cmml" xref="S2.E1.m1.2.2.3.3.3.2">𝑑</ci><ci id="S2.E1.m1.2.2.3.3.3.3.cmml" xref="S2.E1.m1.2.2.3.3.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1"><plus id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.2"></plus><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1.1"><minus id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1"></minus><apply id="S2.E1.m1.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1"><minus id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1"></minus><apply id="S2.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2"><times id="S2.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.1"></times><ci id="S2.E1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2.2">𝑢</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑡</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.2">𝑢</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3"><times id="S2.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.1"></times><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.2">𝑟</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.3">𝑒</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.3.4.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.4">𝑠</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.3.5.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3.3.5">𝑡</ci></apply></apply></apply></apply><apply id="S2.E1.m1.2.2.1.3.cmml" xref="S2.E1.m1.2.2.1.3"><ci id="S2.E1.m1.2.2.1.3.1.cmml" xref="S2.E1.m1.2.2.1.3.1">⋅</ci><ci id="S2.E1.m1.2.2.1.3.2.cmml" xref="S2.E1.m1.2.2.1.3.2">𝑅</ci><ci id="S2.E1.m1.2.2.1.3.3.cmml" xref="S2.E1.m1.2.2.1.3.3">𝐼</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\tau_{m}\frac{du}{dt}=-(u(t)-u_{rest})+R\cdot I</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.2d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT divide start_ARG italic_d italic_u end_ARG start_ARG italic_d italic_t end_ARG = - ( italic_u ( italic_t ) - italic_u start_POSTSUBSCRIPT italic_r italic_e italic_s italic_t end_POSTSUBSCRIPT ) + italic_R ⋅ italic_I</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS2.p1.5" class="ltx_p">where <math id="S2.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\tau_{m}" display="inline"><semantics id="S2.SS1.SSS2.p1.1.m1.1a"><msub id="S2.SS1.SSS2.p1.1.m1.1.1" xref="S2.SS1.SSS2.p1.1.m1.1.1.cmml"><mi id="S2.SS1.SSS2.p1.1.m1.1.1.2" xref="S2.SS1.SSS2.p1.1.m1.1.1.2.cmml">τ</mi><mi id="S2.SS1.SSS2.p1.1.m1.1.1.3" xref="S2.SS1.SSS2.p1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.1.m1.1b"><apply id="S2.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1.2">𝜏</ci><ci id="S2.SS1.SSS2.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.1.m1.1c">\tau_{m}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p1.1.m1.1d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is the membrane time constant, <math id="S2.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="u(t)" display="inline"><semantics id="S2.SS1.SSS2.p1.2.m2.1a"><mrow id="S2.SS1.SSS2.p1.2.m2.1.2" xref="S2.SS1.SSS2.p1.2.m2.1.2.cmml"><mi id="S2.SS1.SSS2.p1.2.m2.1.2.2" xref="S2.SS1.SSS2.p1.2.m2.1.2.2.cmml">u</mi><mo id="S2.SS1.SSS2.p1.2.m2.1.2.1" xref="S2.SS1.SSS2.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.SSS2.p1.2.m2.1.2.3.2" xref="S2.SS1.SSS2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.2.m2.1.2.3.2.1" xref="S2.SS1.SSS2.p1.2.m2.1.2.cmml">(</mo><mi id="S2.SS1.SSS2.p1.2.m2.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.SSS2.p1.2.m2.1.2.3.2.2" xref="S2.SS1.SSS2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.2.m2.1b"><apply id="S2.SS1.SSS2.p1.2.m2.1.2.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.2"><times id="S2.SS1.SSS2.p1.2.m2.1.2.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.2.1"></times><ci id="S2.SS1.SSS2.p1.2.m2.1.2.2.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.2.2">𝑢</ci><ci id="S2.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.2.m2.1c">u(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p1.2.m2.1d">italic_u ( italic_t )</annotation></semantics></math> is the membrane potential as a function of time, <math id="S2.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="u_{rest}" display="inline"><semantics id="S2.SS1.SSS2.p1.3.m3.1a"><msub id="S2.SS1.SSS2.p1.3.m3.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.1.1.2" xref="S2.SS1.SSS2.p1.3.m3.1.1.2.cmml">u</mi><mrow id="S2.SS1.SSS2.p1.3.m3.1.1.3" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.1.1.3.2" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.2.cmml">r</mi><mo id="S2.SS1.SSS2.p1.3.m3.1.1.3.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1.3.3" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.3.cmml">e</mi><mo id="S2.SS1.SSS2.p1.3.m3.1.1.3.1a" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1.3.4" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.4.cmml">s</mi><mo id="S2.SS1.SSS2.p1.3.m3.1.1.3.1b" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1.3.5" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.3.m3.1b"><apply id="S2.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.2">𝑢</ci><apply id="S2.SS1.SSS2.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3"><times id="S2.SS1.SSS2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.1"></times><ci id="S2.SS1.SSS2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.3">𝑒</ci><ci id="S2.SS1.SSS2.p1.3.m3.1.1.3.4.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.4">𝑠</ci><ci id="S2.SS1.SSS2.p1.3.m3.1.1.3.5.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.3.m3.1c">u_{rest}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p1.3.m3.1d">italic_u start_POSTSUBSCRIPT italic_r italic_e italic_s italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the resting potential of the membrane, <math id="S2.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS1.SSS2.p1.4.m4.1a"><mi id="S2.SS1.SSS2.p1.4.m4.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.4.m4.1b"><ci id="S2.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.4.m4.1c">R</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p1.4.m4.1d">italic_R</annotation></semantics></math> is a resistance and <math id="S2.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.SS1.SSS2.p1.5.m5.1a"><mi id="S2.SS1.SSS2.p1.5.m5.1.1" xref="S2.SS1.SSS2.p1.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.5.m5.1b"><ci id="S2.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS2.p1.5.m5.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.5.m5.1c">I</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p1.5.m5.1d">italic_I</annotation></semantics></math> is the incoming current.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">Although this model lacks the ability to describe most of the neuronal dynamics, it is the most common choice for the development of large scale neural networks, mostly because of its efficiency.
</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS2.p3.4" class="ltx_p">More complex I&amp;F models attempt to account for some non-linear dynamics of neurons as a function of the value of their membrane potential in a certain moment in time. Two examples are given by the Exponential Integrate-and-Fire (EIF) model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> and by the Quadratic Integrate-and-Fire neuron (QIF) or Theta neuron <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
As shown in (<a href="#S2.E2" title="2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), EIF model expands on the LIF model by including an exponential dependency on the current state of the membrane potential:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.4" class="ltx_Math" alttext="\tau_{m}\frac{du}{dt}=-(u(t)-u_{rest})+\Delta_{T}\exp{\left(\frac{u(t)-\Theta_{rh}}{\Delta_{T}}\right)}+R\cdot I," display="block"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4.1" xref="S2.E2.m1.4.4.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1" xref="S2.E2.m1.4.4.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.3" xref="S2.E2.m1.4.4.1.1.3.cmml"><msub id="S2.E2.m1.4.4.1.1.3.2" xref="S2.E2.m1.4.4.1.1.3.2.cmml"><mi id="S2.E2.m1.4.4.1.1.3.2.2" xref="S2.E2.m1.4.4.1.1.3.2.2.cmml">τ</mi><mi id="S2.E2.m1.4.4.1.1.3.2.3" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">m</mi></msub><mo id="S2.E2.m1.4.4.1.1.3.1" xref="S2.E2.m1.4.4.1.1.3.1.cmml">⁢</mo><mfrac id="S2.E2.m1.4.4.1.1.3.3" xref="S2.E2.m1.4.4.1.1.3.3.cmml"><mrow id="S2.E2.m1.4.4.1.1.3.3.2" xref="S2.E2.m1.4.4.1.1.3.3.2.cmml"><mi id="S2.E2.m1.4.4.1.1.3.3.2.2" xref="S2.E2.m1.4.4.1.1.3.3.2.2.cmml">d</mi><mo id="S2.E2.m1.4.4.1.1.3.3.2.1" xref="S2.E2.m1.4.4.1.1.3.3.2.1.cmml">⁢</mo><mi id="S2.E2.m1.4.4.1.1.3.3.2.3" xref="S2.E2.m1.4.4.1.1.3.3.2.3.cmml">u</mi></mrow><mrow id="S2.E2.m1.4.4.1.1.3.3.3" xref="S2.E2.m1.4.4.1.1.3.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.3.3.3.2" xref="S2.E2.m1.4.4.1.1.3.3.3.2.cmml">d</mi><mo id="S2.E2.m1.4.4.1.1.3.3.3.1" xref="S2.E2.m1.4.4.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.4.4.1.1.3.3.3.3" xref="S2.E2.m1.4.4.1.1.3.3.3.3.cmml">t</mi></mrow></mfrac></mrow><mo id="S2.E2.m1.4.4.1.1.2" xref="S2.E2.m1.4.4.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.1" xref="S2.E2.m1.4.4.1.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1a" xref="S2.E2.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml">u</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.3.2.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.3.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.2.cmml">u</mi><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.2.cmml">r</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.3.cmml">e</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1a" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.4" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.4.cmml">s</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1b" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.5" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.5.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.2.cmml">+</mo><mrow id="S2.E2.m1.4.4.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.3.cmml"><msub id="S2.E2.m1.4.4.1.1.1.3.2" xref="S2.E2.m1.4.4.1.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.E2.m1.4.4.1.1.1.3.2.2" xref="S2.E2.m1.4.4.1.1.1.3.2.2.cmml">Δ</mi><mi id="S2.E2.m1.4.4.1.1.1.3.2.3" xref="S2.E2.m1.4.4.1.1.1.3.2.3.cmml">T</mi></msub><mo lspace="0.167em" id="S2.E2.m1.4.4.1.1.1.3.1" xref="S2.E2.m1.4.4.1.1.1.3.1.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.1.3.3.2" xref="S2.E2.m1.4.4.1.1.1.3.3.1.cmml"><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">exp</mi><mo id="S2.E2.m1.4.4.1.1.1.3.3.2a" xref="S2.E2.m1.4.4.1.1.1.3.3.1.cmml">⁡</mo><mrow id="S2.E2.m1.4.4.1.1.1.3.3.2.1" xref="S2.E2.m1.4.4.1.1.1.3.3.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.3.3.2.1.1" xref="S2.E2.m1.4.4.1.1.1.3.3.1.cmml">(</mo><mfrac id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.3" xref="S2.E2.m1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.3.2.cmml">u</mi><mo id="S2.E2.m1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.3.1.cmml">⁢</mo><mrow id="S2.E2.m1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.3.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.3.3.2.1" xref="S2.E2.m1.1.1.1.3.cmml">(</mo><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E2.m1.1.1.1.3.3.2.2" xref="S2.E2.m1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.cmml">−</mo><msub id="S2.E2.m1.1.1.1.4" xref="S2.E2.m1.1.1.1.4.cmml"><mi mathvariant="normal" id="S2.E2.m1.1.1.1.4.2" xref="S2.E2.m1.1.1.1.4.2.cmml">Θ</mi><mrow id="S2.E2.m1.1.1.1.4.3" xref="S2.E2.m1.1.1.1.4.3.cmml"><mi id="S2.E2.m1.1.1.1.4.3.2" xref="S2.E2.m1.1.1.1.4.3.2.cmml">r</mi><mo id="S2.E2.m1.1.1.1.4.3.1" xref="S2.E2.m1.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.E2.m1.1.1.1.4.3.3" xref="S2.E2.m1.1.1.1.4.3.3.cmml">h</mi></mrow></msub></mrow><msub id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mi mathvariant="normal" id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml">Δ</mi><mi id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml">T</mi></msub></mfrac><mo id="S2.E2.m1.4.4.1.1.1.3.3.2.1.2" xref="S2.E2.m1.4.4.1.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.2a" xref="S2.E2.m1.4.4.1.1.1.2.cmml">+</mo><mrow id="S2.E2.m1.4.4.1.1.1.4" xref="S2.E2.m1.4.4.1.1.1.4.cmml"><mi id="S2.E2.m1.4.4.1.1.1.4.2" xref="S2.E2.m1.4.4.1.1.1.4.2.cmml">R</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E2.m1.4.4.1.1.1.4.1" xref="S2.E2.m1.4.4.1.1.1.4.1.cmml">⋅</mo><mi id="S2.E2.m1.4.4.1.1.1.4.3" xref="S2.E2.m1.4.4.1.1.1.4.3.cmml">I</mi></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.2" xref="S2.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.1.1.cmml" xref="S2.E2.m1.4.4.1"><eq id="S2.E2.m1.4.4.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2"></eq><apply id="S2.E2.m1.4.4.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.3"><times id="S2.E2.m1.4.4.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.3.1"></times><apply id="S2.E2.m1.4.4.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.3.2.1.cmml" xref="S2.E2.m1.4.4.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.3.2.2.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2">𝜏</ci><ci id="S2.E2.m1.4.4.1.1.3.2.3.cmml" xref="S2.E2.m1.4.4.1.1.3.2.3">𝑚</ci></apply><apply id="S2.E2.m1.4.4.1.1.3.3.cmml" xref="S2.E2.m1.4.4.1.1.3.3"><divide id="S2.E2.m1.4.4.1.1.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.3.3"></divide><apply id="S2.E2.m1.4.4.1.1.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.3.3.2"><times id="S2.E2.m1.4.4.1.1.3.3.2.1.cmml" xref="S2.E2.m1.4.4.1.1.3.3.2.1"></times><ci id="S2.E2.m1.4.4.1.1.3.3.2.2.cmml" xref="S2.E2.m1.4.4.1.1.3.3.2.2">𝑑</ci><ci id="S2.E2.m1.4.4.1.1.3.3.2.3.cmml" xref="S2.E2.m1.4.4.1.1.3.3.2.3">𝑢</ci></apply><apply id="S2.E2.m1.4.4.1.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.3.3.3"><times id="S2.E2.m1.4.4.1.1.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.3.3.3.1"></times><ci id="S2.E2.m1.4.4.1.1.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.3.3.3.2">𝑑</ci><ci id="S2.E2.m1.4.4.1.1.3.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.3.3.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1"><plus id="S2.E2.m1.4.4.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.2"></plus><apply id="S2.E2.m1.4.4.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1"><minus id="S2.E2.m1.4.4.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1"></minus><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1"><minus id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1"></minus><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2"><times id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.2">𝑢</ci><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝑡</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.2">𝑢</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3"><times id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.2">𝑟</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.3">𝑒</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.4.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.4">𝑠</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.5.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.3.5">𝑡</ci></apply></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.3"><times id="S2.E2.m1.4.4.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.3.1"></times><apply id="S2.E2.m1.4.4.1.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.3.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.3.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.3.2.2">Δ</ci><ci id="S2.E2.m1.4.4.1.1.1.3.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.3.2.3">𝑇</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.3.3.2"><exp id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"></exp><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><divide id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1"></divide><apply id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><minus id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.2"></minus><apply id="S2.E2.m1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.3"><times id="S2.E2.m1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.3.1"></times><ci id="S2.E2.m1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.3.2">𝑢</ci><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">𝑡</ci></apply><apply id="S2.E2.m1.1.1.1.4.cmml" xref="S2.E2.m1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.4.1.cmml" xref="S2.E2.m1.1.1.1.4">subscript</csymbol><ci id="S2.E2.m1.1.1.1.4.2.cmml" xref="S2.E2.m1.1.1.1.4.2">Θ</ci><apply id="S2.E2.m1.1.1.1.4.3.cmml" xref="S2.E2.m1.1.1.1.4.3"><times id="S2.E2.m1.1.1.1.4.3.1.cmml" xref="S2.E2.m1.1.1.1.4.3.1"></times><ci id="S2.E2.m1.1.1.1.4.3.2.cmml" xref="S2.E2.m1.1.1.1.4.3.2">𝑟</ci><ci id="S2.E2.m1.1.1.1.4.3.3.cmml" xref="S2.E2.m1.1.1.1.4.3.3">ℎ</ci></apply></apply></apply><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2">Δ</ci><ci id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3">𝑇</ci></apply></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.1.4.cmml" xref="S2.E2.m1.4.4.1.1.1.4"><ci id="S2.E2.m1.4.4.1.1.1.4.1.cmml" xref="S2.E2.m1.4.4.1.1.1.4.1">⋅</ci><ci id="S2.E2.m1.4.4.1.1.1.4.2.cmml" xref="S2.E2.m1.4.4.1.1.1.4.2">𝑅</ci><ci id="S2.E2.m1.4.4.1.1.1.4.3.cmml" xref="S2.E2.m1.4.4.1.1.1.4.3">𝐼</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\tau_{m}\frac{du}{dt}=-(u(t)-u_{rest})+\Delta_{T}\exp{\left(\frac{u(t)-\Theta_{rh}}{\Delta_{T}}\right)}+R\cdot I,</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.4d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT divide start_ARG italic_d italic_u end_ARG start_ARG italic_d italic_t end_ARG = - ( italic_u ( italic_t ) - italic_u start_POSTSUBSCRIPT italic_r italic_e italic_s italic_t end_POSTSUBSCRIPT ) + roman_Δ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT roman_exp ( divide start_ARG italic_u ( italic_t ) - roman_Θ start_POSTSUBSCRIPT italic_r italic_h end_POSTSUBSCRIPT end_ARG start_ARG roman_Δ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_ARG ) + italic_R ⋅ italic_I ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS2.p3.3" class="ltx_p">where <math id="S2.SS1.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\Delta_{T}" display="inline"><semantics id="S2.SS1.SSS2.p3.1.m1.1a"><msub id="S2.SS1.SSS2.p3.1.m1.1.1" xref="S2.SS1.SSS2.p3.1.m1.1.1.cmml"><mi mathvariant="normal" id="S2.SS1.SSS2.p3.1.m1.1.1.2" xref="S2.SS1.SSS2.p3.1.m1.1.1.2.cmml">Δ</mi><mi id="S2.SS1.SSS2.p3.1.m1.1.1.3" xref="S2.SS1.SSS2.p3.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p3.1.m1.1b"><apply id="S2.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p3.1.m1.1.1.1.cmml" xref="S2.SS1.SSS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p3.1.m1.1.1.2.cmml" xref="S2.SS1.SSS2.p3.1.m1.1.1.2">Δ</ci><ci id="S2.SS1.SSS2.p3.1.m1.1.1.3.cmml" xref="S2.SS1.SSS2.p3.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p3.1.m1.1c">\Delta_{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p3.1.m1.1d">roman_Δ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math> is a parameter determining the sharpness of the exponential curve and <math id="S2.SS1.SSS2.p3.2.m2.1" class="ltx_Math" alttext="\Theta_{rh}" display="inline"><semantics id="S2.SS1.SSS2.p3.2.m2.1a"><msub id="S2.SS1.SSS2.p3.2.m2.1.1" xref="S2.SS1.SSS2.p3.2.m2.1.1.cmml"><mi mathvariant="normal" id="S2.SS1.SSS2.p3.2.m2.1.1.2" xref="S2.SS1.SSS2.p3.2.m2.1.1.2.cmml">Θ</mi><mrow id="S2.SS1.SSS2.p3.2.m2.1.1.3" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.cmml"><mi id="S2.SS1.SSS2.p3.2.m2.1.1.3.2" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.2.cmml">r</mi><mo id="S2.SS1.SSS2.p3.2.m2.1.1.3.1" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S2.SS1.SSS2.p3.2.m2.1.1.3.3" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p3.2.m2.1b"><apply id="S2.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p3.2.m2.1.1.1.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p3.2.m2.1.1.2.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1.2">Θ</ci><apply id="S2.SS1.SSS2.p3.2.m2.1.1.3.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1.3"><times id="S2.SS1.SSS2.p3.2.m2.1.1.3.1.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.1"></times><ci id="S2.SS1.SSS2.p3.2.m2.1.1.3.2.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p3.2.m2.1.1.3.3.cmml" xref="S2.SS1.SSS2.p3.2.m2.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p3.2.m2.1c">\Theta_{rh}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p3.2.m2.1d">roman_Θ start_POSTSUBSCRIPT italic_r italic_h end_POSTSUBSCRIPT</annotation></semantics></math> is the rheobase threshold. When <math id="S2.SS1.SSS2.p3.3.m3.1" class="ltx_Math" alttext="u&gt;\Theta_{rh}" display="inline"><semantics id="S2.SS1.SSS2.p3.3.m3.1a"><mrow id="S2.SS1.SSS2.p3.3.m3.1.1" xref="S2.SS1.SSS2.p3.3.m3.1.1.cmml"><mi id="S2.SS1.SSS2.p3.3.m3.1.1.2" xref="S2.SS1.SSS2.p3.3.m3.1.1.2.cmml">u</mi><mo id="S2.SS1.SSS2.p3.3.m3.1.1.1" xref="S2.SS1.SSS2.p3.3.m3.1.1.1.cmml">&gt;</mo><msub id="S2.SS1.SSS2.p3.3.m3.1.1.3" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.cmml"><mi mathvariant="normal" id="S2.SS1.SSS2.p3.3.m3.1.1.3.2" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.2.cmml">Θ</mi><mrow id="S2.SS1.SSS2.p3.3.m3.1.1.3.3" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.cmml"><mi id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.2" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml">r</mi><mo id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.1" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.1.cmml">⁢</mo><mi id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.3" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml">h</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p3.3.m3.1b"><apply id="S2.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1"><gt id="S2.SS1.SSS2.p3.3.m3.1.1.1.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.1"></gt><ci id="S2.SS1.SSS2.p3.3.m3.1.1.2.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.2">𝑢</ci><apply id="S2.SS1.SSS2.p3.3.m3.1.1.3.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p3.3.m3.1.1.3.1.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS2.p3.3.m3.1.1.3.2.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.2">Θ</ci><apply id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3"><times id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.1.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.1"></times><ci id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml" xref="S2.SS1.SSS2.p3.3.m3.1.1.3.3.3">ℎ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p3.3.m3.1c">u&gt;\Theta_{rh}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p3.3.m3.1d">italic_u &gt; roman_Θ start_POSTSUBSCRIPT italic_r italic_h end_POSTSUBSCRIPT</annotation></semantics></math>, the exponential term becomes prominent over the linear one, leading to an upswing of the curve that takes the membrane potential to infinity in finite time.</p>
</div>
<div id="S2.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS2.p4.5" class="ltx_p">The QIF model, given by (<a href="#S2.E3" title="3 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), employs a quadratic dependency from the membrane potential:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.3" class="ltx_Math" alttext="\tau_{m}\frac{du}{dt}=a_{0}(u(t)-u_{c})(u(t)-u_{rest})+R\cdot I," display="block"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1.4" xref="S2.E3.m1.3.3.1.1.4.cmml"><msub id="S2.E3.m1.3.3.1.1.4.2" xref="S2.E3.m1.3.3.1.1.4.2.cmml"><mi id="S2.E3.m1.3.3.1.1.4.2.2" xref="S2.E3.m1.3.3.1.1.4.2.2.cmml">τ</mi><mi id="S2.E3.m1.3.3.1.1.4.2.3" xref="S2.E3.m1.3.3.1.1.4.2.3.cmml">m</mi></msub><mo id="S2.E3.m1.3.3.1.1.4.1" xref="S2.E3.m1.3.3.1.1.4.1.cmml">⁢</mo><mfrac id="S2.E3.m1.3.3.1.1.4.3" xref="S2.E3.m1.3.3.1.1.4.3.cmml"><mrow id="S2.E3.m1.3.3.1.1.4.3.2" xref="S2.E3.m1.3.3.1.1.4.3.2.cmml"><mi id="S2.E3.m1.3.3.1.1.4.3.2.2" xref="S2.E3.m1.3.3.1.1.4.3.2.2.cmml">d</mi><mo id="S2.E3.m1.3.3.1.1.4.3.2.1" xref="S2.E3.m1.3.3.1.1.4.3.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.1.1.4.3.2.3" xref="S2.E3.m1.3.3.1.1.4.3.2.3.cmml">u</mi></mrow><mrow id="S2.E3.m1.3.3.1.1.4.3.3" xref="S2.E3.m1.3.3.1.1.4.3.3.cmml"><mi id="S2.E3.m1.3.3.1.1.4.3.3.2" xref="S2.E3.m1.3.3.1.1.4.3.3.2.cmml">d</mi><mo id="S2.E3.m1.3.3.1.1.4.3.3.1" xref="S2.E3.m1.3.3.1.1.4.3.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.1.1.4.3.3.3" xref="S2.E3.m1.3.3.1.1.4.3.3.3.cmml">t</mi></mrow></mfrac></mrow><mo id="S2.E3.m1.3.3.1.1.3" xref="S2.E3.m1.3.3.1.1.3.cmml">=</mo><mrow id="S2.E3.m1.3.3.1.1.2" xref="S2.E3.m1.3.3.1.1.2.cmml"><mrow id="S2.E3.m1.3.3.1.1.2.2" xref="S2.E3.m1.3.3.1.1.2.2.cmml"><msub id="S2.E3.m1.3.3.1.1.2.2.4" xref="S2.E3.m1.3.3.1.1.2.2.4.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.4.2" xref="S2.E3.m1.3.3.1.1.2.2.4.2.cmml">a</mi><mn id="S2.E3.m1.3.3.1.1.2.2.4.3" xref="S2.E3.m1.3.3.1.1.2.2.4.3.cmml">0</mn></msub><mo id="S2.E3.m1.3.3.1.1.2.2.3" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.1.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml">u</mi><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3.2.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3.2.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S2.E3.m1.3.3.1.1.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.3.3.1.1.2.2.3a" xref="S2.E3.m1.3.3.1.1.2.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.1.2.2.2.1.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.cmml">(</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2.1.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.2.cmml">u</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.3.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.3.2.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.cmml">(</mo><mi id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.3.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.2.2.2.1.1.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.1.cmml">−</mo><msub id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.2.cmml">u</mi><mrow id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.2" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.2.cmml">r</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.3" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.3.cmml">e</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1a" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.4" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.4.cmml">s</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1b" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.5" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.5.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S2.E3.m1.3.3.1.1.2.2.2.1.3" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.2.3" xref="S2.E3.m1.3.3.1.1.2.3.cmml">+</mo><mrow id="S2.E3.m1.3.3.1.1.2.4" xref="S2.E3.m1.3.3.1.1.2.4.cmml"><mi id="S2.E3.m1.3.3.1.1.2.4.2" xref="S2.E3.m1.3.3.1.1.2.4.2.cmml">R</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E3.m1.3.3.1.1.2.4.1" xref="S2.E3.m1.3.3.1.1.2.4.1.cmml">⋅</mo><mi id="S2.E3.m1.3.3.1.1.2.4.3" xref="S2.E3.m1.3.3.1.1.2.4.3.cmml">I</mi></mrow></mrow></mrow><mo id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1"><eq id="S2.E3.m1.3.3.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.3"></eq><apply id="S2.E3.m1.3.3.1.1.4.cmml" xref="S2.E3.m1.3.3.1.1.4"><times id="S2.E3.m1.3.3.1.1.4.1.cmml" xref="S2.E3.m1.3.3.1.1.4.1"></times><apply id="S2.E3.m1.3.3.1.1.4.2.cmml" xref="S2.E3.m1.3.3.1.1.4.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.4.2.1.cmml" xref="S2.E3.m1.3.3.1.1.4.2">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.4.2.2.cmml" xref="S2.E3.m1.3.3.1.1.4.2.2">𝜏</ci><ci id="S2.E3.m1.3.3.1.1.4.2.3.cmml" xref="S2.E3.m1.3.3.1.1.4.2.3">𝑚</ci></apply><apply id="S2.E3.m1.3.3.1.1.4.3.cmml" xref="S2.E3.m1.3.3.1.1.4.3"><divide id="S2.E3.m1.3.3.1.1.4.3.1.cmml" xref="S2.E3.m1.3.3.1.1.4.3"></divide><apply id="S2.E3.m1.3.3.1.1.4.3.2.cmml" xref="S2.E3.m1.3.3.1.1.4.3.2"><times id="S2.E3.m1.3.3.1.1.4.3.2.1.cmml" xref="S2.E3.m1.3.3.1.1.4.3.2.1"></times><ci id="S2.E3.m1.3.3.1.1.4.3.2.2.cmml" xref="S2.E3.m1.3.3.1.1.4.3.2.2">𝑑</ci><ci id="S2.E3.m1.3.3.1.1.4.3.2.3.cmml" xref="S2.E3.m1.3.3.1.1.4.3.2.3">𝑢</ci></apply><apply id="S2.E3.m1.3.3.1.1.4.3.3.cmml" xref="S2.E3.m1.3.3.1.1.4.3.3"><times id="S2.E3.m1.3.3.1.1.4.3.3.1.cmml" xref="S2.E3.m1.3.3.1.1.4.3.3.1"></times><ci id="S2.E3.m1.3.3.1.1.4.3.3.2.cmml" xref="S2.E3.m1.3.3.1.1.4.3.3.2">𝑑</ci><ci id="S2.E3.m1.3.3.1.1.4.3.3.3.cmml" xref="S2.E3.m1.3.3.1.1.4.3.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E3.m1.3.3.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.2"><plus id="S2.E3.m1.3.3.1.1.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.3"></plus><apply id="S2.E3.m1.3.3.1.1.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2"><times id="S2.E3.m1.3.3.1.1.2.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.3"></times><apply id="S2.E3.m1.3.3.1.1.2.2.4.cmml" xref="S2.E3.m1.3.3.1.1.2.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.2.2.4.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.4">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.2.2.4.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.4.2">𝑎</ci><cn type="integer" id="S2.E3.m1.3.3.1.1.2.2.4.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.4.3">0</cn></apply><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1"><minus id="S2.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.1"></minus><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2"><times id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2">𝑢</ci><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">𝑡</ci></apply><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2">𝑢</ci><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.3">𝑐</ci></apply></apply><apply id="S2.E3.m1.3.3.1.1.2.2.2.1.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1"><minus id="S2.E3.m1.3.3.1.1.2.2.2.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.1"></minus><apply id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2"><times id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.1"></times><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.2.2">𝑢</ci><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">𝑡</ci></apply><apply id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.2">𝑢</ci><apply id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3"><times id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.1"></times><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.2">𝑟</ci><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.3">𝑒</ci><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.4.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.4">𝑠</ci><ci id="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.5.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1.1.3.3.5">𝑡</ci></apply></apply></apply></apply><apply id="S2.E3.m1.3.3.1.1.2.4.cmml" xref="S2.E3.m1.3.3.1.1.2.4"><ci id="S2.E3.m1.3.3.1.1.2.4.1.cmml" xref="S2.E3.m1.3.3.1.1.2.4.1">⋅</ci><ci id="S2.E3.m1.3.3.1.1.2.4.2.cmml" xref="S2.E3.m1.3.3.1.1.2.4.2">𝑅</ci><ci id="S2.E3.m1.3.3.1.1.2.4.3.cmml" xref="S2.E3.m1.3.3.1.1.2.4.3">𝐼</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">\tau_{m}\frac{du}{dt}=a_{0}(u(t)-u_{c})(u(t)-u_{rest})+R\cdot I,</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.3d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT divide start_ARG italic_d italic_u end_ARG start_ARG italic_d italic_t end_ARG = italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_u ( italic_t ) - italic_u start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) ( italic_u ( italic_t ) - italic_u start_POSTSUBSCRIPT italic_r italic_e italic_s italic_t end_POSTSUBSCRIPT ) + italic_R ⋅ italic_I ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS2.p4.4" class="ltx_p">where <math id="S2.SS1.SSS2.p4.1.m1.1" class="ltx_Math" alttext="a_{0}" display="inline"><semantics id="S2.SS1.SSS2.p4.1.m1.1a"><msub id="S2.SS1.SSS2.p4.1.m1.1.1" xref="S2.SS1.SSS2.p4.1.m1.1.1.cmml"><mi id="S2.SS1.SSS2.p4.1.m1.1.1.2" xref="S2.SS1.SSS2.p4.1.m1.1.1.2.cmml">a</mi><mn id="S2.SS1.SSS2.p4.1.m1.1.1.3" xref="S2.SS1.SSS2.p4.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p4.1.m1.1b"><apply id="S2.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p4.1.m1.1.1.1.cmml" xref="S2.SS1.SSS2.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p4.1.m1.1.1.2.cmml" xref="S2.SS1.SSS2.p4.1.m1.1.1.2">𝑎</ci><cn type="integer" id="S2.SS1.SSS2.p4.1.m1.1.1.3.cmml" xref="S2.SS1.SSS2.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p4.1.m1.1c">a_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p4.1.m1.1d">italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> is a parameter of the model that regulates the magnitude of the dependency from the membrane potential and <math id="S2.SS1.SSS2.p4.2.m2.1" class="ltx_Math" alttext="u_{c}" display="inline"><semantics id="S2.SS1.SSS2.p4.2.m2.1a"><msub id="S2.SS1.SSS2.p4.2.m2.1.1" xref="S2.SS1.SSS2.p4.2.m2.1.1.cmml"><mi id="S2.SS1.SSS2.p4.2.m2.1.1.2" xref="S2.SS1.SSS2.p4.2.m2.1.1.2.cmml">u</mi><mi id="S2.SS1.SSS2.p4.2.m2.1.1.3" xref="S2.SS1.SSS2.p4.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p4.2.m2.1b"><apply id="S2.SS1.SSS2.p4.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p4.2.m2.1.1.1.cmml" xref="S2.SS1.SSS2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p4.2.m2.1.1.2.cmml" xref="S2.SS1.SSS2.p4.2.m2.1.1.2">𝑢</ci><ci id="S2.SS1.SSS2.p4.2.m2.1.1.3.cmml" xref="S2.SS1.SSS2.p4.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p4.2.m2.1c">u_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p4.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> is a cut-off threshold such that, when <math id="S2.SS1.SSS2.p4.3.m3.1" class="ltx_Math" alttext="I=0" display="inline"><semantics id="S2.SS1.SSS2.p4.3.m3.1a"><mrow id="S2.SS1.SSS2.p4.3.m3.1.1" xref="S2.SS1.SSS2.p4.3.m3.1.1.cmml"><mi id="S2.SS1.SSS2.p4.3.m3.1.1.2" xref="S2.SS1.SSS2.p4.3.m3.1.1.2.cmml">I</mi><mo id="S2.SS1.SSS2.p4.3.m3.1.1.1" xref="S2.SS1.SSS2.p4.3.m3.1.1.1.cmml">=</mo><mn id="S2.SS1.SSS2.p4.3.m3.1.1.3" xref="S2.SS1.SSS2.p4.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p4.3.m3.1b"><apply id="S2.SS1.SSS2.p4.3.m3.1.1.cmml" xref="S2.SS1.SSS2.p4.3.m3.1.1"><eq id="S2.SS1.SSS2.p4.3.m3.1.1.1.cmml" xref="S2.SS1.SSS2.p4.3.m3.1.1.1"></eq><ci id="S2.SS1.SSS2.p4.3.m3.1.1.2.cmml" xref="S2.SS1.SSS2.p4.3.m3.1.1.2">𝐼</ci><cn type="integer" id="S2.SS1.SSS2.p4.3.m3.1.1.3.cmml" xref="S2.SS1.SSS2.p4.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p4.3.m3.1c">I=0</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p4.3.m3.1d">italic_I = 0</annotation></semantics></math> and <math id="S2.SS1.SSS2.p4.4.m4.1" class="ltx_Math" alttext="u&gt;u_{c}" display="inline"><semantics id="S2.SS1.SSS2.p4.4.m4.1a"><mrow id="S2.SS1.SSS2.p4.4.m4.1.1" xref="S2.SS1.SSS2.p4.4.m4.1.1.cmml"><mi id="S2.SS1.SSS2.p4.4.m4.1.1.2" xref="S2.SS1.SSS2.p4.4.m4.1.1.2.cmml">u</mi><mo id="S2.SS1.SSS2.p4.4.m4.1.1.1" xref="S2.SS1.SSS2.p4.4.m4.1.1.1.cmml">&gt;</mo><msub id="S2.SS1.SSS2.p4.4.m4.1.1.3" xref="S2.SS1.SSS2.p4.4.m4.1.1.3.cmml"><mi id="S2.SS1.SSS2.p4.4.m4.1.1.3.2" xref="S2.SS1.SSS2.p4.4.m4.1.1.3.2.cmml">u</mi><mi id="S2.SS1.SSS2.p4.4.m4.1.1.3.3" xref="S2.SS1.SSS2.p4.4.m4.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p4.4.m4.1b"><apply id="S2.SS1.SSS2.p4.4.m4.1.1.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1"><gt id="S2.SS1.SSS2.p4.4.m4.1.1.1.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.1"></gt><ci id="S2.SS1.SSS2.p4.4.m4.1.1.2.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.2">𝑢</ci><apply id="S2.SS1.SSS2.p4.4.m4.1.1.3.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p4.4.m4.1.1.3.1.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS2.p4.4.m4.1.1.3.2.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.3.2">𝑢</ci><ci id="S2.SS1.SSS2.p4.4.m4.1.1.3.3.cmml" xref="S2.SS1.SSS2.p4.4.m4.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p4.4.m4.1c">u&gt;u_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS2.p4.4.m4.1d">italic_u &gt; italic_u start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, the membrane potential grows until the emission of a spike.</p>
</div>
<div id="S2.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS2.p5.1" class="ltx_p">Both the QIF and the EIF bring in a further level of complexity with the inclusion of non-linear dependencies that affect both the computational costs and the ease of analysis, but allow for a more precise generation of spikes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Additionally, a hidden cost lies in the use of two extra parameters in each of them.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S2.F2.sf1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2207.04881/assets/x2.png" id="S2.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="346" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S2.F2.sf2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2207.04881/assets/x3.png" id="S2.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="346" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="S2.F2.sf3" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="/html/2207.04881/assets/x4.png" id="S2.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="346" height="260" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Visualization of the number of events over time. Figure  <a href="#S2.F2.sf1" title="2a ‣ Figure 2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2a</span></a> and <a href="#S2.F2.sf2" title="2b ‣ Figure 2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2b</span></a> for classes "0" and "3" are reported as representative. They depict the count of events for each time-step among samples of one class. Figure  <a href="#S2.F2.sf3" title="2c ‣ Figure 2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2c</span></a> reports the collective mean and variation of events throughout all the classes. As can be seen, events tend to appear always within the same time ranges for all the samples of all the classes in the dataset, thus highlighting the lack of temporal significance. Values on the y-axis are scaled by a factor of <math id="S2.F2.2.m1.1" class="ltx_Math" alttext="10^{5}" display="inline"><semantics id="S2.F2.2.m1.1b"><msup id="S2.F2.2.m1.1.1" xref="S2.F2.2.m1.1.1.cmml"><mn id="S2.F2.2.m1.1.1.2" xref="S2.F2.2.m1.1.1.2.cmml">10</mn><mn id="S2.F2.2.m1.1.1.3" xref="S2.F2.2.m1.1.1.3.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F2.2.m1.1c"><apply id="S2.F2.2.m1.1.1.cmml" xref="S2.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.2.m1.1.1.1.cmml" xref="S2.F2.2.m1.1.1">superscript</csymbol><cn type="integer" id="S2.F2.2.m1.1.1.2.cmml" xref="S2.F2.2.m1.1.1.2">10</cn><cn type="integer" id="S2.F2.2.m1.1.1.3.cmml" xref="S2.F2.2.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.m1.1d">10^{5}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.2.m1.1e">10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Other Multi-Variable I&amp;F Models</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">With the inclusion of adaptation variables within the neuron model, it is possible to account for a larger number of spiking patterns and to render possible the manifestation of spike bursts, spike-adaptation responses and irregular spiking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. This comes at the cost of more differential equations in the model (one per variable) and two relevant examples are given by the Adaptive Exponential Integrate-and-Fire (AdEx) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> neuron model, which builds on top of the EIF, and by Izhikevich’s neuron model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> which builds on top of the QIF.</p>
</div>
<div id="S2.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS3.p2.1" class="ltx_p">A number of neuron models have been theorized in the literature, all answering to different modelling needs or considering different aspects of the observed neuronal behaviours. The ones cited above are amongst the most relevant for what concerns this study and NM computing. In fact, as reported above, the LIF model is the most widely used in the development of SNN for NM applications, but at the same time, models like the AdEx and Izhikevich’s have received a lot of attention in the literature. The EIF and the QIF are on one hand the baseline of the AdEx and Izhikevich’s models respectively, and, on the other hand, a slightly more complex single-variable alternative to the LIF neuron model. As such, in this study, we will focus on these single-variable models.
</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">We are interested in assessing the performance of different neuron models within the context of a Spiking Convolutional Neural Network (SCNN) trained with STDP. Since many factors could determine the outcome of the training, we begin by designing a simple experiment which involves the minor number of structural elements possible. This is done in order to limit the number of components that might impact the overall system performance. Therefore, we use a single-layer convolutional network in which spiking neurons are embedded right after the convolution operation on the input.
The task set to the SCNN is a binary classification task, with the pairs of classes taken from the Neuromorphic MNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and the DVS Gestures dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, which contain event-based data samples.
To develop the learning pipeline, we utilize SpykeTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> as a base framework and build on top of it to include the elements required by this study, such as the diverse spiking neuron models.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Event-based Data</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">To assess the performance of our simple network, we select the two natively neuromorphic datasets mentioned above. We purposely discard other non-native NM datasets as they do not possess a temporal domain, nor data is originally event-based.

<br class="ltx_break">
<br class="ltx_break">Data in the N-MNIST dataset is collected by recording MNIST digits shown on a screen using a moving DVS camera. Specifically, the camera makes the same 3 predefined movements for every sample, each lasting roughly 100 ms. In this way, although the dataset is built on top of a non-neuromorphic one, data samples in the dataset are natively event-based, rather than being converted from a static image. Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the count of events per time for two example classes and throughout all the classes of the dataset.
By contrast, data samples in the DVS Gestures dataset (see Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Spiking Neurons Implementation ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for the inter-class distribution of events over time) are recorded using a fixed DVS camera in front of which participants move their arms according to instructions. Thus, 11 different classes of gestures are obtained, including for example arm rotation, waving or performing air guitar. The 11th class encodes "Other" random movements and is not considered in this work for simplicity.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.5" class="ltx_p">Event data comes in the form of Address Event Representation (AER)-encoded files in which every sample is constituted by a sequence of events. Events are characterized by the specific time at which they occurred, by the location on the 2D plane and by the polarity (negative or positive light change). Similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>, to make data usable by a 2D Convolutional Neural Network (CNN) we populate a 2D image using all the events that took place between time <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_t</annotation></semantics></math> and <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="t+dt" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">t</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">+</mo><mrow id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">d</mi><mo id="S3.SS1.p2.2.m2.1.1.3.1" xref="S3.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">t</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><plus id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></plus><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑡</ci><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><times id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">𝑑</ci><ci id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">t+dt</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_t + italic_d italic_t</annotation></semantics></math>, allowing at most 1 event per (x, y) coordinates. For simplicity, we consider all events as being positive and use a batch size of 1. As a result, the network processes only 1 event map with a time resolution <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="dt" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">d</mi><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><times id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></times><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑑</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">dt</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_d italic_t</annotation></semantics></math> belonging to only 1 sample at a time.
Finally, we characterize each event with a value of <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\frac{1}{t_{s}}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mfrac id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mn id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">1</mn><msub id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">t</mi><mi id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml">s</mi></msub></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><divide id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"></divide><cn type="integer" id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">1</cn><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">𝑡</ci><ci id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\frac{1}{t_{s}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">divide start_ARG 1 end_ARG start_ARG italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> in line with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. This is done in order to preserve the amount of charge that a spike carries regardless of the time-step (<math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="t_{s}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">t</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝑡</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">t_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>) size.
No further pre-processing is applied to the data.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Spiking Neurons Implementation</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">The phenomenological family of neuron models is the best option when developing spiking neural networks, as outlined in Section  <a href="#S2.SS1" title="2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. We specifically concentrate on three integrate and fire neurons, namely the LIF, the QIF and the EIF.
The LIF is the most widely used neuron that embeds a time dependency through the membrane potential leakage. The QIF and the EIF represent valid alternatives given their ability to best fit observed cortical neurons <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. Since they are single-variable models, they stand for a fairer comparison with the LIF, which is single-variable too. Indeed they all depend on the value of the membrane potential, but they all employ different types of dependencies from it. Furthermore, they are the base on which other more complex and popular neuron models are built on, respectively Izhikevich’s neuron and the AdEx neuron model.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">The SpykeTorch framework comes with a simple version of a I&amp;F neuron model.
To enable the use of these neuron models for our experiments, we expand on the framework and implement the above models by adapting the equations provided in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. State updates in the neurons are thus calculated on a per time-step basis, where each call to the neuron layer corresponds to an advancement of <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="t_{s}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">t</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝑡</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">t_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> time from the previously calculated update.
Each neuron layer generates a number of neurons that reflects the size of the incoming post-synaptic currents, multiplied by the number of neuron populations that was specified at creation time. This allows for a more seamless inclusion in any point of an SNN.
When a neuron in a population emits a spike, all the other neurons belonging to the same population are inhibited and put in a refractory state to promote learning in other populations.
Each neuron model is implemented as a class inheriting from a parent Neuron class, in an object-oriented programming style. This differs from the original SpykeTorch implementation style, however, this approach was required for neurons that maintain an internal state. Besides, compatibility with the modules and neurons in SpykeTorch is maintained.
Further features and details are present in the actual implementation, however, these are not relevant to the current study and the authors point the reader to the dedicated repository page for in-depth descriptions.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2207.04881/assets/x5.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="415" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of the number of events over time in the DVS Gestures dataset. The events span across the whole time domain and are very dense for about the first 7 seconds. At that point, they start to decrease in number, however, the tail of the curve continues for a long time. This is due to some of the gestures lasting longer than others.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2207.04881/assets/x6.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="661" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Diagram of the Learning Pipeline. A 2D convolution layer parses the input spike map and produces N feature maps width size WxH. Each value in each feature map is fed to a distinct neuron and the one spiking earliest is chosen as a winner by the WTA mechanism. STDP weight updates are then applied to the convolution kernel corresponding to that neuron. For ease of visualization, neuron populations are here represented as individual neurons, but each of them actually contains WxH neurons, i.e. like one feature map.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>SCNN and Learning</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">We develop a simple feedforward convolutional network for our experiments, with a single convolutional layer that parses the input and connects it to the spiking neurons. Figure  <a href="#S3.F4" title="Figure 4 ‣ 3.2 Spiking Neurons Implementation ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the pipeline for a better understanding. The weights of the kernel can be thought of as being synapse strengths and the resulting feature map is the input to a set of spiking neurons arranged accordingly.
In other words, the convolution represents the connectivity scheme for the spiking neurons. The use of a convolutional layer to connect inputs with the spiking neurons allows them to more easily learn spatial features.
The weights of the convolutional layer are the only parameters being learnt by the network and no pooling nor normalization is applied.

<br class="ltx_break">
<br class="ltx_break">We use the STDP presented and used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> as an unsupervised learning rule. By employing this kind of learning rule and, therefore, using it to evaluate neurons, we want to take a step closer to local feedforward learning, which is believed to be the key to exploit the potentials of neuromorphic engineering at its best <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
The mentioned STDP rule applies the following weight updates:

<br class="ltx_break">
<br class="ltx_break"></p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="\centering\Delta W_{i,j}=\begin{cases}A^{+}\times(W_{i,j}-LB)\times(UB-W_{i,j})\quad\text{if}\quad T_{j}\leq T_{i},\\
A^{-}\times(W_{i,j}-LB)\times(UB-W_{i,j})\quad\text{if}\quad T_{j}&gt;T_{i},\end{cases}\@add@centering" display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.5" xref="S3.E4.m1.4.5.cmml"><mrow id="S3.E4.m1.4.5.2" xref="S3.E4.m1.4.5.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.4.5.2.2" xref="S3.E4.m1.4.5.2.2.cmml">Δ</mi><mo id="S3.E4.m1.4.5.2.1" xref="S3.E4.m1.4.5.2.1.cmml">⁢</mo><msub id="S3.E4.m1.4.5.2.3" xref="S3.E4.m1.4.5.2.3.cmml"><mi id="S3.E4.m1.4.5.2.3.2" xref="S3.E4.m1.4.5.2.3.2.cmml">W</mi><mrow id="S3.E4.m1.4.4.2.4" xref="S3.E4.m1.4.4.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml">i</mi><mo id="S3.E4.m1.4.4.2.4.1" xref="S3.E4.m1.4.4.2.3.cmml">,</mo><mi id="S3.E4.m1.4.4.2.2" xref="S3.E4.m1.4.4.2.2.cmml">j</mi></mrow></msub></mrow><mo id="S3.E4.m1.4.5.1" xref="S3.E4.m1.4.5.1.cmml">=</mo><mrow id="S3.E4.m1.2.2" xref="S3.E4.m1.4.5.3.1.cmml"><mo id="S3.E4.m1.2.2.3" xref="S3.E4.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.2.2.2" xref="S3.E4.m1.4.5.3.1.cmml"><mtr id="S3.E4.m1.2.2.2a" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.2.2.2b" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.6" xref="S3.E4.m1.1.1.1.1.1.1.6.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.3.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.2.cmml">A</mi><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.3.cmml">+</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3.cmml">×</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.2.cmml">W</mi><mrow id="S3.E4.m1.1.1.1.1.1.1.2.2.4" xref="S3.E4.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">i</mi><mo id="S3.E4.m1.1.1.1.1.1.1.2.2.4.1" xref="S3.E4.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><mi id="S3.E4.m1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.2.cmml">L</mi><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.3.cmml">B</mi></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3a" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3.cmml">×</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.2.cmml">U</mi><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.1.cmml">⁢</mo><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.3.cmml">B</mi></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.1.cmml">−</mo><msub id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.2.cmml">W</mi><mrow id="S3.E4.m1.1.1.1.1.1.1.4.2.4" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.3.1.1" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1.cmml">i</mi><mo id="S3.E4.m1.1.1.1.1.1.1.4.2.4.1" xref="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml">,</mo><mi id="S3.E4.m1.1.1.1.1.1.1.4.2.2" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mspace width="1em" id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.3.cmml"></mspace><mtext id="S3.E4.m1.1.1.1.1.1.1.5" xref="S3.E4.m1.1.1.1.1.1.1.5a.cmml">if</mtext><mspace width="1em" id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.4" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.3.cmml"></mspace><msub id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.2.cmml">T</mi><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.3.cmml">j</mi></msub></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.6.1.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.3.cmml">≤</mo><msub id="S3.E4.m1.1.1.1.1.1.1.6.1.4" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.4.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4.2.cmml">T</mi><mi id="S3.E4.m1.1.1.1.1.1.1.6.1.4.3" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4.3.cmml">i</mi></msub></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.6.2" xref="S3.E4.m1.1.1.1.1.1.1.6.1.cmml">,</mo></mrow></mtd><mtd id="S3.E4.m1.2.2.2c" xref="S3.E4.m1.4.5.3.1.1.cmml"></mtd></mtr><mtr id="S3.E4.m1.2.2.2d" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.2.2.2e" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.1.1.6" xref="S3.E4.m1.2.2.2.2.1.1.6.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.3.cmml"><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.cmml"><msup id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.2.cmml">A</mi><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.3.cmml">−</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3.cmml">×</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.2.cmml">W</mi><mrow id="S3.E4.m1.2.2.2.2.1.1.2.2.4" xref="S3.E4.m1.2.2.2.2.1.1.2.2.3.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.1.1.1.cmml">i</mi><mo id="S3.E4.m1.2.2.2.2.1.1.2.2.4.1" xref="S3.E4.m1.2.2.2.2.1.1.2.2.3.cmml">,</mo><mi id="S3.E4.m1.2.2.2.2.1.1.2.2.2" xref="S3.E4.m1.2.2.2.2.1.1.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.2.cmml">L</mi><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.3.cmml">B</mi></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3a" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3.cmml">×</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.2.cmml">U</mi><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.1.cmml">⁢</mo><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.3.cmml">B</mi></mrow><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.1" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.1.cmml">−</mo><msub id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.2.cmml">W</mi><mrow id="S3.E4.m1.2.2.2.2.1.1.4.2.4" xref="S3.E4.m1.2.2.2.2.1.1.4.2.3.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.3.1.1" xref="S3.E4.m1.2.2.2.2.1.1.3.1.1.cmml">i</mi><mo id="S3.E4.m1.2.2.2.2.1.1.4.2.4.1" xref="S3.E4.m1.2.2.2.2.1.1.4.2.3.cmml">,</mo><mi id="S3.E4.m1.2.2.2.2.1.1.4.2.2" xref="S3.E4.m1.2.2.2.2.1.1.4.2.2.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mspace width="1em" id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.3.cmml"></mspace><mtext id="S3.E4.m1.2.2.2.2.1.1.5" xref="S3.E4.m1.2.2.2.2.1.1.5a.cmml">if</mtext><mspace width="1em" id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.4" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.3.cmml"></mspace><msub id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.2.cmml">T</mi><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.3.cmml">j</mi></msub></mrow><mo id="S3.E4.m1.2.2.2.2.1.1.6.1.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.3.cmml">&gt;</mo><msub id="S3.E4.m1.2.2.2.2.1.1.6.1.4" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4.cmml"><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.4.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4.2.cmml">T</mi><mi id="S3.E4.m1.2.2.2.2.1.1.6.1.4.3" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4.3.cmml">i</mi></msub></mrow><mo id="S3.E4.m1.2.2.2.2.1.1.6.2" xref="S3.E4.m1.2.2.2.2.1.1.6.1.cmml">,</mo></mrow></mtd><mtd id="S3.E4.m1.2.2.2f" xref="S3.E4.m1.4.5.3.1.1.cmml"></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.5.cmml" xref="S3.E4.m1.4.5"><eq id="S3.E4.m1.4.5.1.cmml" xref="S3.E4.m1.4.5.1"></eq><apply id="S3.E4.m1.4.5.2.cmml" xref="S3.E4.m1.4.5.2"><times id="S3.E4.m1.4.5.2.1.cmml" xref="S3.E4.m1.4.5.2.1"></times><ci id="S3.E4.m1.4.5.2.2.cmml" xref="S3.E4.m1.4.5.2.2">Δ</ci><apply id="S3.E4.m1.4.5.2.3.cmml" xref="S3.E4.m1.4.5.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.5.2.3.1.cmml" xref="S3.E4.m1.4.5.2.3">subscript</csymbol><ci id="S3.E4.m1.4.5.2.3.2.cmml" xref="S3.E4.m1.4.5.2.3.2">𝑊</ci><list id="S3.E4.m1.4.4.2.3.cmml" xref="S3.E4.m1.4.4.2.4"><ci id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1">𝑖</ci><ci id="S3.E4.m1.4.4.2.2.cmml" xref="S3.E4.m1.4.4.2.2">𝑗</ci></list></apply></apply><apply id="S3.E4.m1.4.5.3.1.cmml" xref="S3.E4.m1.2.2"><csymbol cd="latexml" id="S3.E4.m1.4.5.3.1.1.cmml" xref="S3.E4.m1.2.2.3">cases</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6"><leq id="S3.E4.m1.1.1.1.1.1.1.6.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.3"></leq><list id="S3.E4.m1.1.1.1.1.1.1.6.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.3"></times><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.2">𝐴</ci><plus id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.4.3"></plus></apply><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.1"></minus><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.2.2">𝑊</ci><list id="S3.E4.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.4"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1">𝑖</ci><ci id="S3.E4.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2.2">𝑗</ci></list></apply><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.2">𝐿</ci><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.1.1.1.3.3">𝐵</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1"><minus id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.1"></minus><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2"><times id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.1"></times><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.2">𝑈</ci><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.2.3">𝐵</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.1.1.1.2.1.1.3.2">𝑊</ci><list id="S3.E4.m1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.4"><ci id="S3.E4.m1.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3.1.1">𝑖</ci><ci id="S3.E4.m1.1.1.1.1.1.1.4.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.4.2.2">𝑗</ci></list></apply></apply></apply><ci id="S3.E4.m1.1.1.1.1.1.1.5a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.5"><mtext id="S3.E4.m1.1.1.1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.1.1.1.5">if</mtext></ci><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.2">𝑇</ci><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.2.2.2.3">𝑗</ci></apply></list><apply id="S3.E4.m1.1.1.1.1.1.1.6.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.6.1.4.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.4.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4.2">𝑇</ci><ci id="S3.E4.m1.1.1.1.1.1.1.6.1.4.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.6.1.4.3">𝑖</ci></apply></apply><ci id="S3.E4.m1.4.5.3.1.3a.cmml" xref="S3.E4.m1.2.2"><mtext id="S3.E4.m1.4.5.3.1.3.cmml" xref="S3.E4.m1.2.2.3">𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒</mtext></ci><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6"><gt id="S3.E4.m1.2.2.2.2.1.1.6.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.3"></gt><list id="S3.E4.m1.2.2.2.2.1.1.6.1.2.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2"><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1"><times id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.3"></times><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4">superscript</csymbol><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.2">𝐴</ci><minus id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.4.3"></minus></apply><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1"><minus id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.1"></minus><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.2.2">𝑊</ci><list id="S3.E4.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.2.2.4"><ci id="S3.E4.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.1.1.1">𝑖</ci><ci id="S3.E4.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.2.2.2">𝑗</ci></list></apply><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3"><times id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.2">𝐿</ci><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.1.1.1.3.3">𝐵</ci></apply></apply><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1"><minus id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.1"></minus><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2"><times id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.1"></times><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.2">𝑈</ci><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.2.3">𝐵</ci></apply><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.1.1.1.2.1.1.3.2">𝑊</ci><list id="S3.E4.m1.2.2.2.2.1.1.4.2.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.4.2.4"><ci id="S3.E4.m1.2.2.2.2.1.1.3.1.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.3.1.1">𝑖</ci><ci id="S3.E4.m1.2.2.2.2.1.1.4.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.4.2.2">𝑗</ci></list></apply></apply></apply><ci id="S3.E4.m1.2.2.2.2.1.1.5a.cmml" xref="S3.E4.m1.2.2.2.2.1.1.5"><mtext id="S3.E4.m1.2.2.2.2.1.1.5.cmml" xref="S3.E4.m1.2.2.2.2.1.1.5">if</mtext></ci><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.2">𝑇</ci><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.2.2.2.3">𝑗</ci></apply></list><apply id="S3.E4.m1.2.2.2.2.1.1.6.1.4.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.1.6.1.4.1.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.4.2.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4.2">𝑇</ci><ci id="S3.E4.m1.2.2.2.2.1.1.6.1.4.3.cmml" xref="S3.E4.m1.2.2.2.2.1.1.6.1.4.3">𝑖</ci></apply></apply><ci id="S3.E4.m1.4.5.3.1.5a.cmml" xref="S3.E4.m1.2.2"><mtext id="S3.E4.m1.4.5.3.1.5.cmml" xref="S3.E4.m1.2.2.3">𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\centering\Delta W_{i,j}=\begin{cases}A^{+}\times(W_{i,j}-LB)\times(UB-W_{i,j})\quad\text{if}\quad T_{j}\leq T_{i},\\
A^{-}\times(W_{i,j}-LB)\times(UB-W_{i,j})\quad\text{if}\quad T_{j}&gt;T_{i},\end{cases}\@add@centering</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.4d">roman_Δ italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = { start_ROW start_CELL italic_A start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT × ( italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT - italic_L italic_B ) × ( italic_U italic_B - italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) if italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ≤ italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL italic_A start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT × ( italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT - italic_L italic_B ) × ( italic_U italic_B - italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) if italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT &gt; italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , end_CELL start_CELL end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.11" class="ltx_p">where <math id="S3.SS3.p2.1.m1.2" class="ltx_Math" alttext="W_{i,j}" display="inline"><semantics id="S3.SS3.p2.1.m1.2a"><msub id="S3.SS3.p2.1.m1.2.3" xref="S3.SS3.p2.1.m1.2.3.cmml"><mi id="S3.SS3.p2.1.m1.2.3.2" xref="S3.SS3.p2.1.m1.2.3.2.cmml">W</mi><mrow id="S3.SS3.p2.1.m1.2.2.2.4" xref="S3.SS3.p2.1.m1.2.2.2.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS3.p2.1.m1.2.2.2.4.1" xref="S3.SS3.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS3.p2.1.m1.2.2.2.2" xref="S3.SS3.p2.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.2b"><apply id="S3.SS3.p2.1.m1.2.3.cmml" xref="S3.SS3.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.2.3.1.cmml" xref="S3.SS3.p2.1.m1.2.3">subscript</csymbol><ci id="S3.SS3.p2.1.m1.2.3.2.cmml" xref="S3.SS3.p2.1.m1.2.3.2">𝑊</ci><list id="S3.SS3.p2.1.m1.2.2.2.3.cmml" xref="S3.SS3.p2.1.m1.2.2.2.4"><ci id="S3.SS3.p2.1.m1.1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1">𝑖</ci><ci id="S3.SS3.p2.1.m1.2.2.2.2.cmml" xref="S3.SS3.p2.1.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.2c">W_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.2d">italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is the weight of the synapse connecting neuron <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_j</annotation></semantics></math> (pre-synaptic) to neuron <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_i</annotation></semantics></math> (post-synaptic), <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="LB" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mrow id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">L</mi><mo id="S3.SS3.p2.4.m4.1.1.1" xref="S3.SS3.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><times id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1.1"></times><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">𝐿</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">LB</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_L italic_B</annotation></semantics></math> and <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="UB" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">U</mi><mo id="S3.SS3.p2.5.m5.1.1.1" xref="S3.SS3.p2.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><times id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1.1"></times><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝑈</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">UB</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">italic_U italic_B</annotation></semantics></math> are a lower and an upper bound value respectively, <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="T_{j}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><msub id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">T</mi><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝑇</ci><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">T_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m6.1d">italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is the timing of the spike emitted by neuron <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mi id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><ci id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.7.m7.1d">italic_j</annotation></semantics></math>, <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><msub id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">T</mi><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝑇</ci><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.8.m8.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> the timing of the spike emitted by neuron <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><mi id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><ci id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.9.m9.1d">italic_i</annotation></semantics></math>, and <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="A^{+}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><msup id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml">A</mi><mo id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1">superscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2">𝐴</ci><plus id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">A^{+}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.10.m10.1d">italic_A start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math> and <math id="S3.SS3.p2.11.m11.1" class="ltx_Math" alttext="A^{-}" display="inline"><semantics id="S3.SS3.p2.11.m11.1a"><msup id="S3.SS3.p2.11.m11.1.1" xref="S3.SS3.p2.11.m11.1.1.cmml"><mi id="S3.SS3.p2.11.m11.1.1.2" xref="S3.SS3.p2.11.m11.1.1.2.cmml">A</mi><mo id="S3.SS3.p2.11.m11.1.1.3" xref="S3.SS3.p2.11.m11.1.1.3.cmml">−</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m11.1b"><apply id="S3.SS3.p2.11.m11.1.1.cmml" xref="S3.SS3.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m11.1.1.1.cmml" xref="S3.SS3.p2.11.m11.1.1">superscript</csymbol><ci id="S3.SS3.p2.11.m11.1.1.2.cmml" xref="S3.SS3.p2.11.m11.1.1.2">𝐴</ci><minus id="S3.SS3.p2.11.m11.1.1.3.cmml" xref="S3.SS3.p2.11.m11.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m11.1c">A^{-}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.11.m11.1d">italic_A start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT</annotation></semantics></math> are two parameters used to scale the weight update.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.16" class="ltx_p">It is thus a system of two parabolic equations that are applied depending on whether Long Term Potentiation (LTP) or Long Term Depression (LTD) needs to take place. One of the consequences of using this learning rule is that weight updates are self-regularized. In fact, the closer the weights get to the boundary values, the smaller the updates will be, allowing the weights to be refined more granularly as the learning proceeds. Another aspect that is important to highlight is in how this learning rule is applied. While the original theorization of Hebbian rules such as STDP states that the weight update should be proportional in value and sign on the time-difference between the post- and the pre-synaptic spikes, in a software implementation some approximations are required. Therefore, for each time-step of the execution, we apply LTP on weights connected to input locations where there has been a spike, and LTD in all the others.
In order to promote competitive and differentiated feature learning, we also employ a k-Winners Take All (WTA) (with k=1) learning paradigm. WTA allows only k neurons per time-step to be eligible for STDP updates, specifically the ones firing sooner.

<br class="ltx_break">
<br class="ltx_break">Finally, as an homeostatic mechanism to allow neurons to keep on firing despite the changes in their synaptic weights, we re-calculate individual neurons’ thresholds according to (<a href="#S3.E5" title="5 ‣ 3.3 SCNN and Learning ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). This form of adaptive thresholding is often required when employing STDP, and is a common practice for SNNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="V_{thresh}=\lambda\cdot R\cdot A\cdot\frac{t_{s}}{\tau_{m}}\cdot\overline{W}\cdot(W_{k}\cdot H_{k})\cdot n_{c}," display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml">V</mi><mrow id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.cmml">h</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1a" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.3.3.4" xref="S3.E5.m1.1.1.1.1.3.3.4.cmml">r</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1b" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.3.3.5" xref="S3.E5.m1.1.1.1.1.3.3.5.cmml">e</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1c" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.3.3.6" xref="S3.E5.m1.1.1.1.1.3.3.6.cmml">s</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1d" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E5.m1.1.1.1.1.3.3.7" xref="S3.E5.m1.1.1.1.1.3.3.7.cmml">h</mi></mrow></msub><mo id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3.cmml">λ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S3.E5.m1.1.1.1.1.1.4" xref="S3.E5.m1.1.1.1.1.1.4.cmml">R</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2a" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S3.E5.m1.1.1.1.1.1.5" xref="S3.E5.m1.1.1.1.1.1.5.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2b" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><mfrac id="S3.E5.m1.1.1.1.1.1.6" xref="S3.E5.m1.1.1.1.1.1.6.cmml"><msub id="S3.E5.m1.1.1.1.1.1.6.2" xref="S3.E5.m1.1.1.1.1.1.6.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.6.2.2" xref="S3.E5.m1.1.1.1.1.1.6.2.2.cmml">t</mi><mi id="S3.E5.m1.1.1.1.1.1.6.2.3" xref="S3.E5.m1.1.1.1.1.1.6.2.3.cmml">s</mi></msub><msub id="S3.E5.m1.1.1.1.1.1.6.3" xref="S3.E5.m1.1.1.1.1.1.6.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.6.3.2" xref="S3.E5.m1.1.1.1.1.1.6.3.2.cmml">τ</mi><mi id="S3.E5.m1.1.1.1.1.1.6.3.3" xref="S3.E5.m1.1.1.1.1.1.6.3.3.cmml">m</mi></msub></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2c" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><mover accent="true" id="S3.E5.m1.1.1.1.1.1.7" xref="S3.E5.m1.1.1.1.1.1.7.cmml"><mi id="S3.E5.m1.1.1.1.1.1.7.2" xref="S3.E5.m1.1.1.1.1.1.7.2.cmml">W</mi><mo id="S3.E5.m1.1.1.1.1.1.7.1" xref="S3.E5.m1.1.1.1.1.1.7.1.cmml">¯</mo></mover><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2d" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml">H</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E5.m1.1.1.1.1.1.2e" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.1.8" xref="S3.E5.m1.1.1.1.1.1.8.cmml"><mi id="S3.E5.m1.1.1.1.1.1.8.2" xref="S3.E5.m1.1.1.1.1.1.8.2.cmml">n</mi><mi id="S3.E5.m1.1.1.1.1.1.8.3" xref="S3.E5.m1.1.1.1.1.1.8.3.cmml">c</mi></msub></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"></eq><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2">𝑉</ci><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><times id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.1"></times><ci id="S3.E5.m1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2">𝑡</ci><ci id="S3.E5.m1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3">ℎ</ci><ci id="S3.E5.m1.1.1.1.1.3.3.4.cmml" xref="S3.E5.m1.1.1.1.1.3.3.4">𝑟</ci><ci id="S3.E5.m1.1.1.1.1.3.3.5.cmml" xref="S3.E5.m1.1.1.1.1.3.3.5">𝑒</ci><ci id="S3.E5.m1.1.1.1.1.3.3.6.cmml" xref="S3.E5.m1.1.1.1.1.3.3.6">𝑠</ci><ci id="S3.E5.m1.1.1.1.1.3.3.7.cmml" xref="S3.E5.m1.1.1.1.1.3.3.7">ℎ</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><ci id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2">⋅</ci><ci id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3">𝜆</ci><ci id="S3.E5.m1.1.1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.1.4">𝑅</ci><ci id="S3.E5.m1.1.1.1.1.1.5.cmml" xref="S3.E5.m1.1.1.1.1.1.5">𝐴</ci><apply id="S3.E5.m1.1.1.1.1.1.6.cmml" xref="S3.E5.m1.1.1.1.1.1.6"><divide id="S3.E5.m1.1.1.1.1.1.6.1.cmml" xref="S3.E5.m1.1.1.1.1.1.6"></divide><apply id="S3.E5.m1.1.1.1.1.1.6.2.cmml" xref="S3.E5.m1.1.1.1.1.1.6.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.6.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.6.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.6.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.6.2.2">𝑡</ci><ci id="S3.E5.m1.1.1.1.1.1.6.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.6.2.3">𝑠</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.6.3.cmml" xref="S3.E5.m1.1.1.1.1.1.6.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.6.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.6.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.6.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.6.3.2">𝜏</ci><ci id="S3.E5.m1.1.1.1.1.1.6.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.6.3.3">𝑚</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.7.cmml" xref="S3.E5.m1.1.1.1.1.1.7"><ci id="S3.E5.m1.1.1.1.1.1.7.1.cmml" xref="S3.E5.m1.1.1.1.1.1.7.1">¯</ci><ci id="S3.E5.m1.1.1.1.1.1.7.2.cmml" xref="S3.E5.m1.1.1.1.1.1.7.2">𝑊</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2">𝑊</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2">𝐻</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.8.cmml" xref="S3.E5.m1.1.1.1.1.1.8"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.8.1.cmml" xref="S3.E5.m1.1.1.1.1.1.8">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.8.2.cmml" xref="S3.E5.m1.1.1.1.1.1.8.2">𝑛</ci><ci id="S3.E5.m1.1.1.1.1.1.8.3.cmml" xref="S3.E5.m1.1.1.1.1.1.8.3">𝑐</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">V_{thresh}=\lambda\cdot R\cdot A\cdot\frac{t_{s}}{\tau_{m}}\cdot\overline{W}\cdot(W_{k}\cdot H_{k})\cdot n_{c},</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_V start_POSTSUBSCRIPT italic_t italic_h italic_r italic_e italic_s italic_h end_POSTSUBSCRIPT = italic_λ ⋅ italic_R ⋅ italic_A ⋅ divide start_ARG italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_ARG ⋅ over¯ start_ARG italic_W end_ARG ⋅ ( italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ⋅ italic_n start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.1" class="ltx_p">and since <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\tau_{m}=R\cdot C" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><msub id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2.2" xref="S3.SS3.p3.1.m1.1.1.2.2.cmml">τ</mi><mi id="S3.SS3.p3.1.m1.1.1.2.3" xref="S3.SS3.p3.1.m1.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.3.2.cmml">R</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.1.m1.1.1.3.1" xref="S3.SS3.p3.1.m1.1.1.3.1.cmml">⋅</mo><mi id="S3.SS3.p3.1.m1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.3.3.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><eq id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></eq><apply id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2.2">𝜏</ci><ci id="S3.SS3.p3.1.m1.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.1.1.2.3">𝑚</ci></apply><apply id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><ci id="S3.SS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.3.1">⋅</ci><ci id="S3.SS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.3.2">𝑅</ci><ci id="S3.SS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\tau_{m}=R\cdot C</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = italic_R ⋅ italic_C</annotation></semantics></math>, we can equivalently re-write:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="V_{thresh}=\lambda\cdot A\cdot\frac{t_{s}}{C}\cdot\overline{W}\cdot(W_{k}\cdot H_{k}\cdot N_{c})," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml">V</mi><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml">h</mi><mo id="S3.E6.m1.1.1.1.1.3.3.1a" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.3.4" xref="S3.E6.m1.1.1.1.1.3.3.4.cmml">r</mi><mo id="S3.E6.m1.1.1.1.1.3.3.1b" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.3.5" xref="S3.E6.m1.1.1.1.1.3.3.5.cmml">e</mi><mo id="S3.E6.m1.1.1.1.1.3.3.1c" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.3.6" xref="S3.E6.m1.1.1.1.1.3.3.6.cmml">s</mi><mo id="S3.E6.m1.1.1.1.1.3.3.1d" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.3.3.7" xref="S3.E6.m1.1.1.1.1.3.3.7.cmml">h</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml">λ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S3.E6.m1.1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.1.4.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.2a" xref="S3.E6.m1.1.1.1.1.1.2.cmml">⋅</mo><mfrac id="S3.E6.m1.1.1.1.1.1.5" xref="S3.E6.m1.1.1.1.1.1.5.cmml"><msub id="S3.E6.m1.1.1.1.1.1.5.2" xref="S3.E6.m1.1.1.1.1.1.5.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.5.2.2" xref="S3.E6.m1.1.1.1.1.1.5.2.2.cmml">t</mi><mi id="S3.E6.m1.1.1.1.1.1.5.2.3" xref="S3.E6.m1.1.1.1.1.1.5.2.3.cmml">s</mi></msub><mi id="S3.E6.m1.1.1.1.1.1.5.3" xref="S3.E6.m1.1.1.1.1.1.5.3.cmml">C</mi></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.2b" xref="S3.E6.m1.1.1.1.1.1.2.cmml">⋅</mo><mover accent="true" id="S3.E6.m1.1.1.1.1.1.6" xref="S3.E6.m1.1.1.1.1.1.6.cmml"><mi id="S3.E6.m1.1.1.1.1.1.6.2" xref="S3.E6.m1.1.1.1.1.1.6.2.cmml">W</mi><mo id="S3.E6.m1.1.1.1.1.1.6.1" xref="S3.E6.m1.1.1.1.1.1.6.1.cmml">¯</mo></mover><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.2c" xref="S3.E6.m1.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.2.cmml">H</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E6.m1.1.1.1.1.1.1.1.1.1a" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S3.E6.m1.1.1.1.1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.cmml">N</mi><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.4.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></eq><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2">𝑉</ci><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">𝑡</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3">ℎ</ci><ci id="S3.E6.m1.1.1.1.1.3.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.3.4">𝑟</ci><ci id="S3.E6.m1.1.1.1.1.3.3.5.cmml" xref="S3.E6.m1.1.1.1.1.3.3.5">𝑒</ci><ci id="S3.E6.m1.1.1.1.1.3.3.6.cmml" xref="S3.E6.m1.1.1.1.1.3.3.6">𝑠</ci><ci id="S3.E6.m1.1.1.1.1.3.3.7.cmml" xref="S3.E6.m1.1.1.1.1.3.3.7">ℎ</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.2">⋅</ci><ci id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3">𝜆</ci><ci id="S3.E6.m1.1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.1.4">𝐴</ci><apply id="S3.E6.m1.1.1.1.1.1.5.cmml" xref="S3.E6.m1.1.1.1.1.1.5"><divide id="S3.E6.m1.1.1.1.1.1.5.1.cmml" xref="S3.E6.m1.1.1.1.1.1.5"></divide><apply id="S3.E6.m1.1.1.1.1.1.5.2.cmml" xref="S3.E6.m1.1.1.1.1.1.5.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.5.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.5.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.5.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.5.2.2">𝑡</ci><ci id="S3.E6.m1.1.1.1.1.1.5.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.5.2.3">𝑠</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.5.3.cmml" xref="S3.E6.m1.1.1.1.1.1.5.3">𝐶</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.6.cmml" xref="S3.E6.m1.1.1.1.1.1.6"><ci id="S3.E6.m1.1.1.1.1.1.6.1.cmml" xref="S3.E6.m1.1.1.1.1.1.6.1">¯</ci><ci id="S3.E6.m1.1.1.1.1.1.6.2.cmml" xref="S3.E6.m1.1.1.1.1.1.6.2">𝑊</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1">⋅</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.2">𝑊</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.2">𝐻</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.2">𝑁</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.4.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">V_{thresh}=\lambda\cdot A\cdot\frac{t_{s}}{C}\cdot\overline{W}\cdot(W_{k}\cdot H_{k}\cdot N_{c}),</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">italic_V start_POSTSUBSCRIPT italic_t italic_h italic_r italic_e italic_s italic_h end_POSTSUBSCRIPT = italic_λ ⋅ italic_A ⋅ divide start_ARG italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG italic_C end_ARG ⋅ over¯ start_ARG italic_W end_ARG ⋅ ( italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.15" class="ltx_p">where <math id="S3.SS3.p3.2.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p3.2.m1.1a"><mi id="S3.SS3.p3.2.m1.1.1" xref="S3.SS3.p3.2.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m1.1b"><ci id="S3.SS3.p3.2.m1.1.1.cmml" xref="S3.SS3.p3.2.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m1.1d">italic_A</annotation></semantics></math> is the amplitude of the spike, in our case assigned to be <math id="S3.SS3.p3.3.m2.1" class="ltx_Math" alttext="A=\frac{1}{t_{s}}" display="inline"><semantics id="S3.SS3.p3.3.m2.1a"><mrow id="S3.SS3.p3.3.m2.1.1" xref="S3.SS3.p3.3.m2.1.1.cmml"><mi id="S3.SS3.p3.3.m2.1.1.2" xref="S3.SS3.p3.3.m2.1.1.2.cmml">A</mi><mo id="S3.SS3.p3.3.m2.1.1.1" xref="S3.SS3.p3.3.m2.1.1.1.cmml">=</mo><mfrac id="S3.SS3.p3.3.m2.1.1.3" xref="S3.SS3.p3.3.m2.1.1.3.cmml"><mn id="S3.SS3.p3.3.m2.1.1.3.2" xref="S3.SS3.p3.3.m2.1.1.3.2.cmml">1</mn><msub id="S3.SS3.p3.3.m2.1.1.3.3" xref="S3.SS3.p3.3.m2.1.1.3.3.cmml"><mi id="S3.SS3.p3.3.m2.1.1.3.3.2" xref="S3.SS3.p3.3.m2.1.1.3.3.2.cmml">t</mi><mi id="S3.SS3.p3.3.m2.1.1.3.3.3" xref="S3.SS3.p3.3.m2.1.1.3.3.3.cmml">s</mi></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m2.1b"><apply id="S3.SS3.p3.3.m2.1.1.cmml" xref="S3.SS3.p3.3.m2.1.1"><eq id="S3.SS3.p3.3.m2.1.1.1.cmml" xref="S3.SS3.p3.3.m2.1.1.1"></eq><ci id="S3.SS3.p3.3.m2.1.1.2.cmml" xref="S3.SS3.p3.3.m2.1.1.2">𝐴</ci><apply id="S3.SS3.p3.3.m2.1.1.3.cmml" xref="S3.SS3.p3.3.m2.1.1.3"><divide id="S3.SS3.p3.3.m2.1.1.3.1.cmml" xref="S3.SS3.p3.3.m2.1.1.3"></divide><cn type="integer" id="S3.SS3.p3.3.m2.1.1.3.2.cmml" xref="S3.SS3.p3.3.m2.1.1.3.2">1</cn><apply id="S3.SS3.p3.3.m2.1.1.3.3.cmml" xref="S3.SS3.p3.3.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m2.1.1.3.3.1.cmml" xref="S3.SS3.p3.3.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p3.3.m2.1.1.3.3.2.cmml" xref="S3.SS3.p3.3.m2.1.1.3.3.2">𝑡</ci><ci id="S3.SS3.p3.3.m2.1.1.3.3.3.cmml" xref="S3.SS3.p3.3.m2.1.1.3.3.3">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m2.1c">A=\frac{1}{t_{s}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m2.1d">italic_A = divide start_ARG 1 end_ARG start_ARG italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>, <math id="S3.SS3.p3.4.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS3.p3.4.m3.1a"><mi id="S3.SS3.p3.4.m3.1.1" xref="S3.SS3.p3.4.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m3.1b"><ci id="S3.SS3.p3.4.m3.1.1.cmml" xref="S3.SS3.p3.4.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m3.1d">italic_R</annotation></semantics></math> is the resistance, <math id="S3.SS3.p3.5.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS3.p3.5.m4.1a"><mi id="S3.SS3.p3.5.m4.1.1" xref="S3.SS3.p3.5.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m4.1b"><ci id="S3.SS3.p3.5.m4.1.1.cmml" xref="S3.SS3.p3.5.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m4.1d">italic_C</annotation></semantics></math> is the capacity, <math id="S3.SS3.p3.6.m5.1" class="ltx_Math" alttext="\tau_{m}" display="inline"><semantics id="S3.SS3.p3.6.m5.1a"><msub id="S3.SS3.p3.6.m5.1.1" xref="S3.SS3.p3.6.m5.1.1.cmml"><mi id="S3.SS3.p3.6.m5.1.1.2" xref="S3.SS3.p3.6.m5.1.1.2.cmml">τ</mi><mi id="S3.SS3.p3.6.m5.1.1.3" xref="S3.SS3.p3.6.m5.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m5.1b"><apply id="S3.SS3.p3.6.m5.1.1.cmml" xref="S3.SS3.p3.6.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m5.1.1.1.cmml" xref="S3.SS3.p3.6.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m5.1.1.2.cmml" xref="S3.SS3.p3.6.m5.1.1.2">𝜏</ci><ci id="S3.SS3.p3.6.m5.1.1.3.cmml" xref="S3.SS3.p3.6.m5.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m5.1c">\tau_{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m5.1d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is the membrane time constant, <math id="S3.SS3.p3.7.m6.1" class="ltx_Math" alttext="\overline{W}" display="inline"><semantics id="S3.SS3.p3.7.m6.1a"><mover accent="true" id="S3.SS3.p3.7.m6.1.1" xref="S3.SS3.p3.7.m6.1.1.cmml"><mi id="S3.SS3.p3.7.m6.1.1.2" xref="S3.SS3.p3.7.m6.1.1.2.cmml">W</mi><mo id="S3.SS3.p3.7.m6.1.1.1" xref="S3.SS3.p3.7.m6.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m6.1b"><apply id="S3.SS3.p3.7.m6.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1"><ci id="S3.SS3.p3.7.m6.1.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1.1">¯</ci><ci id="S3.SS3.p3.7.m6.1.1.2.cmml" xref="S3.SS3.p3.7.m6.1.1.2">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m6.1c">\overline{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m6.1d">over¯ start_ARG italic_W end_ARG</annotation></semantics></math> is the average value of the synaptic weights, <math id="S3.SS3.p3.8.m7.1" class="ltx_Math" alttext="W_{k}" display="inline"><semantics id="S3.SS3.p3.8.m7.1a"><msub id="S3.SS3.p3.8.m7.1.1" xref="S3.SS3.p3.8.m7.1.1.cmml"><mi id="S3.SS3.p3.8.m7.1.1.2" xref="S3.SS3.p3.8.m7.1.1.2.cmml">W</mi><mi id="S3.SS3.p3.8.m7.1.1.3" xref="S3.SS3.p3.8.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m7.1b"><apply id="S3.SS3.p3.8.m7.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.2">𝑊</ci><ci id="S3.SS3.p3.8.m7.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m7.1c">W_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m7.1d">italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>, <math id="S3.SS3.p3.9.m8.1" class="ltx_Math" alttext="H_{k}" display="inline"><semantics id="S3.SS3.p3.9.m8.1a"><msub id="S3.SS3.p3.9.m8.1.1" xref="S3.SS3.p3.9.m8.1.1.cmml"><mi id="S3.SS3.p3.9.m8.1.1.2" xref="S3.SS3.p3.9.m8.1.1.2.cmml">H</mi><mi id="S3.SS3.p3.9.m8.1.1.3" xref="S3.SS3.p3.9.m8.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m8.1b"><apply id="S3.SS3.p3.9.m8.1.1.cmml" xref="S3.SS3.p3.9.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.9.m8.1.1.1.cmml" xref="S3.SS3.p3.9.m8.1.1">subscript</csymbol><ci id="S3.SS3.p3.9.m8.1.1.2.cmml" xref="S3.SS3.p3.9.m8.1.1.2">𝐻</ci><ci id="S3.SS3.p3.9.m8.1.1.3.cmml" xref="S3.SS3.p3.9.m8.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m8.1c">H_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.9.m8.1d">italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S3.SS3.p3.10.m9.1" class="ltx_Math" alttext="N_{c}" display="inline"><semantics id="S3.SS3.p3.10.m9.1a"><msub id="S3.SS3.p3.10.m9.1.1" xref="S3.SS3.p3.10.m9.1.1.cmml"><mi id="S3.SS3.p3.10.m9.1.1.2" xref="S3.SS3.p3.10.m9.1.1.2.cmml">N</mi><mi id="S3.SS3.p3.10.m9.1.1.3" xref="S3.SS3.p3.10.m9.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m9.1b"><apply id="S3.SS3.p3.10.m9.1.1.cmml" xref="S3.SS3.p3.10.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m9.1.1.1.cmml" xref="S3.SS3.p3.10.m9.1.1">subscript</csymbol><ci id="S3.SS3.p3.10.m9.1.1.2.cmml" xref="S3.SS3.p3.10.m9.1.1.2">𝑁</ci><ci id="S3.SS3.p3.10.m9.1.1.3.cmml" xref="S3.SS3.p3.10.m9.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m9.1c">N_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.10.m9.1d">italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> are the width, height and depth (number of channels) of the synaptic kernel, and <math id="S3.SS3.p3.11.m10.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p3.11.m10.1a"><mi id="S3.SS3.p3.11.m10.1.1" xref="S3.SS3.p3.11.m10.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m10.1b"><ci id="S3.SS3.p3.11.m10.1.1.cmml" xref="S3.SS3.p3.11.m10.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m10.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.11.m10.1d">italic_λ</annotation></semantics></math> is a regulation parameter that takes values in the range <math id="S3.SS3.p3.12.m11.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S3.SS3.p3.12.m11.2a"><mrow id="S3.SS3.p3.12.m11.2.3.2" xref="S3.SS3.p3.12.m11.2.3.1.cmml"><mo stretchy="false" id="S3.SS3.p3.12.m11.2.3.2.1" xref="S3.SS3.p3.12.m11.2.3.1.cmml">[</mo><mn id="S3.SS3.p3.12.m11.1.1" xref="S3.SS3.p3.12.m11.1.1.cmml">0</mn><mo id="S3.SS3.p3.12.m11.2.3.2.2" xref="S3.SS3.p3.12.m11.2.3.1.cmml">,</mo><mn id="S3.SS3.p3.12.m11.2.2" xref="S3.SS3.p3.12.m11.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS3.p3.12.m11.2.3.2.3" xref="S3.SS3.p3.12.m11.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m11.2b"><interval closure="closed" id="S3.SS3.p3.12.m11.2.3.1.cmml" xref="S3.SS3.p3.12.m11.2.3.2"><cn type="integer" id="S3.SS3.p3.12.m11.1.1.cmml" xref="S3.SS3.p3.12.m11.1.1">0</cn><cn type="integer" id="S3.SS3.p3.12.m11.2.2.cmml" xref="S3.SS3.p3.12.m11.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m11.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.12.m11.2d">[ 0 , 1 ]</annotation></semantics></math>.
In (<a href="#S3.E6" title="6 ‣ 3.3 SCNN and Learning ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), the term <math id="S3.SS3.p3.13.m12.1" class="ltx_Math" alttext="A\cdot\frac{t_{s}}{C}\cdot\overline{W}" display="inline"><semantics id="S3.SS3.p3.13.m12.1a"><mrow id="S3.SS3.p3.13.m12.1.1" xref="S3.SS3.p3.13.m12.1.1.cmml"><mi id="S3.SS3.p3.13.m12.1.1.2" xref="S3.SS3.p3.13.m12.1.1.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.13.m12.1.1.1" xref="S3.SS3.p3.13.m12.1.1.1.cmml">⋅</mo><mfrac id="S3.SS3.p3.13.m12.1.1.3" xref="S3.SS3.p3.13.m12.1.1.3.cmml"><msub id="S3.SS3.p3.13.m12.1.1.3.2" xref="S3.SS3.p3.13.m12.1.1.3.2.cmml"><mi id="S3.SS3.p3.13.m12.1.1.3.2.2" xref="S3.SS3.p3.13.m12.1.1.3.2.2.cmml">t</mi><mi id="S3.SS3.p3.13.m12.1.1.3.2.3" xref="S3.SS3.p3.13.m12.1.1.3.2.3.cmml">s</mi></msub><mi id="S3.SS3.p3.13.m12.1.1.3.3" xref="S3.SS3.p3.13.m12.1.1.3.3.cmml">C</mi></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.13.m12.1.1.1a" xref="S3.SS3.p3.13.m12.1.1.1.cmml">⋅</mo><mover accent="true" id="S3.SS3.p3.13.m12.1.1.4" xref="S3.SS3.p3.13.m12.1.1.4.cmml"><mi id="S3.SS3.p3.13.m12.1.1.4.2" xref="S3.SS3.p3.13.m12.1.1.4.2.cmml">W</mi><mo id="S3.SS3.p3.13.m12.1.1.4.1" xref="S3.SS3.p3.13.m12.1.1.4.1.cmml">¯</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.13.m12.1b"><apply id="S3.SS3.p3.13.m12.1.1.cmml" xref="S3.SS3.p3.13.m12.1.1"><ci id="S3.SS3.p3.13.m12.1.1.1.cmml" xref="S3.SS3.p3.13.m12.1.1.1">⋅</ci><ci id="S3.SS3.p3.13.m12.1.1.2.cmml" xref="S3.SS3.p3.13.m12.1.1.2">𝐴</ci><apply id="S3.SS3.p3.13.m12.1.1.3.cmml" xref="S3.SS3.p3.13.m12.1.1.3"><divide id="S3.SS3.p3.13.m12.1.1.3.1.cmml" xref="S3.SS3.p3.13.m12.1.1.3"></divide><apply id="S3.SS3.p3.13.m12.1.1.3.2.cmml" xref="S3.SS3.p3.13.m12.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.13.m12.1.1.3.2.1.cmml" xref="S3.SS3.p3.13.m12.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p3.13.m12.1.1.3.2.2.cmml" xref="S3.SS3.p3.13.m12.1.1.3.2.2">𝑡</ci><ci id="S3.SS3.p3.13.m12.1.1.3.2.3.cmml" xref="S3.SS3.p3.13.m12.1.1.3.2.3">𝑠</ci></apply><ci id="S3.SS3.p3.13.m12.1.1.3.3.cmml" xref="S3.SS3.p3.13.m12.1.1.3.3">𝐶</ci></apply><apply id="S3.SS3.p3.13.m12.1.1.4.cmml" xref="S3.SS3.p3.13.m12.1.1.4"><ci id="S3.SS3.p3.13.m12.1.1.4.1.cmml" xref="S3.SS3.p3.13.m12.1.1.4.1">¯</ci><ci id="S3.SS3.p3.13.m12.1.1.4.2.cmml" xref="S3.SS3.p3.13.m12.1.1.4.2">𝑊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.13.m12.1c">A\cdot\frac{t_{s}}{C}\cdot\overline{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.13.m12.1d">italic_A ⋅ divide start_ARG italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_ARG start_ARG italic_C end_ARG ⋅ over¯ start_ARG italic_W end_ARG</annotation></semantics></math>, can be explained as being the average effect perceived on the membrane potential as a result of a single spike, whereas the second term, <math id="S3.SS3.p3.14.m13.1" class="ltx_Math" alttext="(W_{k}\cdot H_{k})\cdot n_{c}" display="inline"><semantics id="S3.SS3.p3.14.m13.1a"><mrow id="S3.SS3.p3.14.m13.1.1" xref="S3.SS3.p3.14.m13.1.1.cmml"><mrow id="S3.SS3.p3.14.m13.1.1.1.1" xref="S3.SS3.p3.14.m13.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.14.m13.1.1.1.1.2" xref="S3.SS3.p3.14.m13.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.14.m13.1.1.1.1.1" xref="S3.SS3.p3.14.m13.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.14.m13.1.1.1.1.1.2" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p3.14.m13.1.1.1.1.1.2.2" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2.2.cmml">W</mi><mi id="S3.SS3.p3.14.m13.1.1.1.1.1.2.3" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p3.14.m13.1.1.1.1.1.1" xref="S3.SS3.p3.14.m13.1.1.1.1.1.1.cmml">⋅</mo><msub id="S3.SS3.p3.14.m13.1.1.1.1.1.3" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.14.m13.1.1.1.1.1.3.2" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3.2.cmml">H</mi><mi id="S3.SS3.p3.14.m13.1.1.1.1.1.3.3" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3.3.cmml">k</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS3.p3.14.m13.1.1.1.1.3" xref="S3.SS3.p3.14.m13.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS3.p3.14.m13.1.1.2" xref="S3.SS3.p3.14.m13.1.1.2.cmml">⋅</mo><msub id="S3.SS3.p3.14.m13.1.1.3" xref="S3.SS3.p3.14.m13.1.1.3.cmml"><mi id="S3.SS3.p3.14.m13.1.1.3.2" xref="S3.SS3.p3.14.m13.1.1.3.2.cmml">n</mi><mi id="S3.SS3.p3.14.m13.1.1.3.3" xref="S3.SS3.p3.14.m13.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.14.m13.1b"><apply id="S3.SS3.p3.14.m13.1.1.cmml" xref="S3.SS3.p3.14.m13.1.1"><ci id="S3.SS3.p3.14.m13.1.1.2.cmml" xref="S3.SS3.p3.14.m13.1.1.2">⋅</ci><apply id="S3.SS3.p3.14.m13.1.1.1.1.1.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1"><ci id="S3.SS3.p3.14.m13.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.1">⋅</ci><apply id="S3.SS3.p3.14.m13.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.14.m13.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.14.m13.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2.2">𝑊</ci><ci id="S3.SS3.p3.14.m13.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.SS3.p3.14.m13.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.14.m13.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.14.m13.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3.2">𝐻</ci><ci id="S3.SS3.p3.14.m13.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.14.m13.1.1.1.1.1.3.3">𝑘</ci></apply></apply><apply id="S3.SS3.p3.14.m13.1.1.3.cmml" xref="S3.SS3.p3.14.m13.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.14.m13.1.1.3.1.cmml" xref="S3.SS3.p3.14.m13.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.14.m13.1.1.3.2.cmml" xref="S3.SS3.p3.14.m13.1.1.3.2">𝑛</ci><ci id="S3.SS3.p3.14.m13.1.1.3.3.cmml" xref="S3.SS3.p3.14.m13.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.14.m13.1c">(W_{k}\cdot H_{k})\cdot n_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.14.m13.1d">( italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ⋅ italic_n start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, scales this effect to the size of the synaptic kernel. Therefore, (<a href="#S3.E6" title="6 ‣ 3.3 SCNN and Learning ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) calculates what would be the average post-synaptic potential perceived in the case the input was dense with spikes. The parameter <math id="S3.SS3.p3.15.m14.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS3.p3.15.m14.1a"><mi id="S3.SS3.p3.15.m14.1.1" xref="S3.SS3.p3.15.m14.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.15.m14.1b"><ci id="S3.SS3.p3.15.m14.1.1.cmml" xref="S3.SS3.p3.15.m14.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.15.m14.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.15.m14.1d">italic_λ</annotation></semantics></math> serves as a regulation of what percentage of this amount would be necessary to reach before emitting a spike.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Classification</h3>

<div id="S3.SS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS4.p1.1" class="ltx_p">Because we employ an unsupervised learning rule, labels are not used at any point during the learning of the weights. However, labels are needed to classify data samples, therefore we adopt a system similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> and count, for each neuron, the number of times it spiked in response to samples having a given label. At the end of the training phase, each neuron is assigned the label for which it spiked the most during training.

<br class="ltx_break">During the inference phase, for each data sample, a sequence of spikes is collected and weighted depending on the order they arrived. These are then summed and the label corresponding to the highest value is selected as the classification outcome.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Hyper-parameter Optimization</h3>

<div id="S3.SS5.p1" class="ltx_para ltx_noindent">
<p id="S3.SS5.p1.1" class="ltx_p">Defining a good set of parameters for a machine learning system is a non-trivial task. This often requires a lot of expertise and hand tuning and is very error-prone. In order to reduce the possibility of selecting sub-optimal parameters for neurons which would result in poor performance, we thus make use of an optimization system to find reasonably good parameters for our experiments.
To this extent, we employ the BOHB optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> using the HpBandSter library. This technique combines Bayesian Optimization (BO) and Hyperband (HB), a resource allocation and early stopping strategy.
As a result, we can draw more robust conclusions about the performance of the neurons.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 4 </span>Results</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">We train the SCNN outlined in Section  <a href="#S3" title="Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> using a subset of the N-MNIST and the DVS Gestures datasets. Indeed, in order to not present the network with too difficult a job, we define a binary classification task between 2 classes from the datasets. More specifically, we randomly select 4 distinct couples of classes from each dataset and define, for each, a separate binary classification task. In this way, we aim to obtain more generalizable results and to reduce the dependency of the results on a particular coupling.
Furthermore, the order in which data is presented to the SCNN might be influential in a system employing STDP as a learning rule. This is due to the fact that STDP rewards and builds on the inputs that are presented earlier. Therefore, to ensure independence from this behaviour of STDP, we repeat every experiment a total of 11 times per task.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Same Hyper-Parameters Training</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">We first conduct our experiments using hand-tuned hyper-parameters. These were found by a trial-and-error practice and represent a set of parameters that enabled learning for the task at hand. This means that neurons using these parameters were able to emit spikes and to have the weights adjusted in a way that enabled the learning of representations of the inputs.
Where possible, we adopt the same hyper-parameters for all the neurons in all the experiments on each dataset. Since the QIF and the EIF models introduce 2 different hyper-parameters each, each of them undergoes a further hand-tuning.
Results of the training sessions are shown in Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Same Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for the N-MNIST-based tasks and in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Same Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for the DVS Gesture-based tasks. Here, for every task and neuron model, are reported the average and best test accuracies achieved, calculated according to (<a href="#S4.E7" title="7 ‣ 4.1 Same Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>):</p>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.1" class="ltx_Math" alttext="accuracy=\frac{TP+TN}{TP+TN+FT+FN}," display="block"><semantics id="S4.E7.m1.1a"><mrow id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.1.cmml"><mrow id="S4.E7.m1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.cmml"><mrow id="S4.E7.m1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.2.cmml"><mi id="S4.E7.m1.1.1.1.1.2.2" xref="S4.E7.m1.1.1.1.1.2.2.cmml">a</mi><mo id="S4.E7.m1.1.1.1.1.2.1" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.3" xref="S4.E7.m1.1.1.1.1.2.3.cmml">c</mi><mo id="S4.E7.m1.1.1.1.1.2.1a" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.4" xref="S4.E7.m1.1.1.1.1.2.4.cmml">c</mi><mo id="S4.E7.m1.1.1.1.1.2.1b" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.5" xref="S4.E7.m1.1.1.1.1.2.5.cmml">u</mi><mo id="S4.E7.m1.1.1.1.1.2.1c" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.6" xref="S4.E7.m1.1.1.1.1.2.6.cmml">r</mi><mo id="S4.E7.m1.1.1.1.1.2.1d" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.7" xref="S4.E7.m1.1.1.1.1.2.7.cmml">a</mi><mo id="S4.E7.m1.1.1.1.1.2.1e" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.8" xref="S4.E7.m1.1.1.1.1.2.8.cmml">c</mi><mo id="S4.E7.m1.1.1.1.1.2.1f" xref="S4.E7.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.2.9" xref="S4.E7.m1.1.1.1.1.2.9.cmml">y</mi></mrow><mo id="S4.E7.m1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.cmml">=</mo><mfrac id="S4.E7.m1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.3.cmml"><mrow id="S4.E7.m1.1.1.1.1.3.2" xref="S4.E7.m1.1.1.1.1.3.2.cmml"><mrow id="S4.E7.m1.1.1.1.1.3.2.2" xref="S4.E7.m1.1.1.1.1.3.2.2.cmml"><mi id="S4.E7.m1.1.1.1.1.3.2.2.2" xref="S4.E7.m1.1.1.1.1.3.2.2.2.cmml">T</mi><mo id="S4.E7.m1.1.1.1.1.3.2.2.1" xref="S4.E7.m1.1.1.1.1.3.2.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.2.2.3" xref="S4.E7.m1.1.1.1.1.3.2.2.3.cmml">P</mi></mrow><mo id="S4.E7.m1.1.1.1.1.3.2.1" xref="S4.E7.m1.1.1.1.1.3.2.1.cmml">+</mo><mrow id="S4.E7.m1.1.1.1.1.3.2.3" xref="S4.E7.m1.1.1.1.1.3.2.3.cmml"><mi id="S4.E7.m1.1.1.1.1.3.2.3.2" xref="S4.E7.m1.1.1.1.1.3.2.3.2.cmml">T</mi><mo id="S4.E7.m1.1.1.1.1.3.2.3.1" xref="S4.E7.m1.1.1.1.1.3.2.3.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.2.3.3" xref="S4.E7.m1.1.1.1.1.3.2.3.3.cmml">N</mi></mrow></mrow><mrow id="S4.E7.m1.1.1.1.1.3.3" xref="S4.E7.m1.1.1.1.1.3.3.cmml"><mrow id="S4.E7.m1.1.1.1.1.3.3.2" xref="S4.E7.m1.1.1.1.1.3.3.2.cmml"><mi id="S4.E7.m1.1.1.1.1.3.3.2.2" xref="S4.E7.m1.1.1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E7.m1.1.1.1.1.3.3.2.1" xref="S4.E7.m1.1.1.1.1.3.3.2.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.3.2.3" xref="S4.E7.m1.1.1.1.1.3.3.2.3.cmml">P</mi></mrow><mo id="S4.E7.m1.1.1.1.1.3.3.1" xref="S4.E7.m1.1.1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E7.m1.1.1.1.1.3.3.3" xref="S4.E7.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.E7.m1.1.1.1.1.3.3.3.2" xref="S4.E7.m1.1.1.1.1.3.3.3.2.cmml">T</mi><mo id="S4.E7.m1.1.1.1.1.3.3.3.1" xref="S4.E7.m1.1.1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.3.3.3" xref="S4.E7.m1.1.1.1.1.3.3.3.3.cmml">N</mi></mrow><mo id="S4.E7.m1.1.1.1.1.3.3.1a" xref="S4.E7.m1.1.1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E7.m1.1.1.1.1.3.3.4" xref="S4.E7.m1.1.1.1.1.3.3.4.cmml"><mi id="S4.E7.m1.1.1.1.1.3.3.4.2" xref="S4.E7.m1.1.1.1.1.3.3.4.2.cmml">F</mi><mo id="S4.E7.m1.1.1.1.1.3.3.4.1" xref="S4.E7.m1.1.1.1.1.3.3.4.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.3.4.3" xref="S4.E7.m1.1.1.1.1.3.3.4.3.cmml">T</mi></mrow><mo id="S4.E7.m1.1.1.1.1.3.3.1b" xref="S4.E7.m1.1.1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E7.m1.1.1.1.1.3.3.5" xref="S4.E7.m1.1.1.1.1.3.3.5.cmml"><mi id="S4.E7.m1.1.1.1.1.3.3.5.2" xref="S4.E7.m1.1.1.1.1.3.3.5.2.cmml">F</mi><mo id="S4.E7.m1.1.1.1.1.3.3.5.1" xref="S4.E7.m1.1.1.1.1.3.3.5.1.cmml">⁢</mo><mi id="S4.E7.m1.1.1.1.1.3.3.5.3" xref="S4.E7.m1.1.1.1.1.3.3.5.3.cmml">N</mi></mrow></mrow></mfrac></mrow><mo id="S4.E7.m1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1"><eq id="S4.E7.m1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1"></eq><apply id="S4.E7.m1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.2"><times id="S4.E7.m1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.1.1.2.1"></times><ci id="S4.E7.m1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.1.1.1.1.2.2">𝑎</ci><ci id="S4.E7.m1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.1.1.1.1.2.3">𝑐</ci><ci id="S4.E7.m1.1.1.1.1.2.4.cmml" xref="S4.E7.m1.1.1.1.1.2.4">𝑐</ci><ci id="S4.E7.m1.1.1.1.1.2.5.cmml" xref="S4.E7.m1.1.1.1.1.2.5">𝑢</ci><ci id="S4.E7.m1.1.1.1.1.2.6.cmml" xref="S4.E7.m1.1.1.1.1.2.6">𝑟</ci><ci id="S4.E7.m1.1.1.1.1.2.7.cmml" xref="S4.E7.m1.1.1.1.1.2.7">𝑎</ci><ci id="S4.E7.m1.1.1.1.1.2.8.cmml" xref="S4.E7.m1.1.1.1.1.2.8">𝑐</ci><ci id="S4.E7.m1.1.1.1.1.2.9.cmml" xref="S4.E7.m1.1.1.1.1.2.9">𝑦</ci></apply><apply id="S4.E7.m1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.3"><divide id="S4.E7.m1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.1.1.1.1.3"></divide><apply id="S4.E7.m1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.1.1.1.1.3.2"><plus id="S4.E7.m1.1.1.1.1.3.2.1.cmml" xref="S4.E7.m1.1.1.1.1.3.2.1"></plus><apply id="S4.E7.m1.1.1.1.1.3.2.2.cmml" xref="S4.E7.m1.1.1.1.1.3.2.2"><times id="S4.E7.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.E7.m1.1.1.1.1.3.2.2.1"></times><ci id="S4.E7.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E7.m1.1.1.1.1.3.2.2.2">𝑇</ci><ci id="S4.E7.m1.1.1.1.1.3.2.2.3.cmml" xref="S4.E7.m1.1.1.1.1.3.2.2.3">𝑃</ci></apply><apply id="S4.E7.m1.1.1.1.1.3.2.3.cmml" xref="S4.E7.m1.1.1.1.1.3.2.3"><times id="S4.E7.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E7.m1.1.1.1.1.3.2.3.1"></times><ci id="S4.E7.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E7.m1.1.1.1.1.3.2.3.2">𝑇</ci><ci id="S4.E7.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.E7.m1.1.1.1.1.3.2.3.3">𝑁</ci></apply></apply><apply id="S4.E7.m1.1.1.1.1.3.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3"><plus id="S4.E7.m1.1.1.1.1.3.3.1.cmml" xref="S4.E7.m1.1.1.1.1.3.3.1"></plus><apply id="S4.E7.m1.1.1.1.1.3.3.2.cmml" xref="S4.E7.m1.1.1.1.1.3.3.2"><times id="S4.E7.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E7.m1.1.1.1.1.3.3.2.1"></times><ci id="S4.E7.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E7.m1.1.1.1.1.3.3.2.2">𝑇</ci><ci id="S4.E7.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3.2.3">𝑃</ci></apply><apply id="S4.E7.m1.1.1.1.1.3.3.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3.3"><times id="S4.E7.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.E7.m1.1.1.1.1.3.3.3.1"></times><ci id="S4.E7.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.E7.m1.1.1.1.1.3.3.3.2">𝑇</ci><ci id="S4.E7.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3.3.3">𝑁</ci></apply><apply id="S4.E7.m1.1.1.1.1.3.3.4.cmml" xref="S4.E7.m1.1.1.1.1.3.3.4"><times id="S4.E7.m1.1.1.1.1.3.3.4.1.cmml" xref="S4.E7.m1.1.1.1.1.3.3.4.1"></times><ci id="S4.E7.m1.1.1.1.1.3.3.4.2.cmml" xref="S4.E7.m1.1.1.1.1.3.3.4.2">𝐹</ci><ci id="S4.E7.m1.1.1.1.1.3.3.4.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3.4.3">𝑇</ci></apply><apply id="S4.E7.m1.1.1.1.1.3.3.5.cmml" xref="S4.E7.m1.1.1.1.1.3.3.5"><times id="S4.E7.m1.1.1.1.1.3.3.5.1.cmml" xref="S4.E7.m1.1.1.1.1.3.3.5.1"></times><ci id="S4.E7.m1.1.1.1.1.3.3.5.2.cmml" xref="S4.E7.m1.1.1.1.1.3.3.5.2">𝐹</ci><ci id="S4.E7.m1.1.1.1.1.3.3.5.3.cmml" xref="S4.E7.m1.1.1.1.1.3.3.5.3">𝑁</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">accuracy=\frac{TP+TN}{TP+TN+FT+FN},</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.1d">italic_a italic_c italic_c italic_u italic_r italic_a italic_c italic_y = divide start_ARG italic_T italic_P + italic_T italic_N end_ARG start_ARG italic_T italic_P + italic_T italic_N + italic_F italic_T + italic_F italic_N end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p1.2" class="ltx_p">where TP stands for true positive, TN for true negative, FT for false true and FN for false negative.
On each column (task), the best average score and the absolute best score are highlighted in bold.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Table of results on the N-MNIST dataset. In each cell, the mean accuracy <math id="S4.T1.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.2.m1.1b"><mo id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.1c"><csymbol cd="latexml" id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.m1.1e">±</annotation></semantics></math> the standard deviation values are followed by the best accuracy found (after the comma). Values are rounded up to the closest second decimal value.</figcaption>
<div id="S4.T1.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:243.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(90.0pt,-50.5pt) scale(1.7095912575967,1.7095912575967) ;">
<table id="S4.T1.14.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.14.12.13.1" class="ltx_tr">
<th id="S4.T1.14.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Neuron Model</th>
<th id="S4.T1.14.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">0 vs 1</th>
<th id="S4.T1.14.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">2 vs 9</th>
<th id="S4.T1.14.12.13.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3 vs 7</th>
<th id="S4.T1.14.12.13.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">4 vs 8</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.6.4.4" class="ltx_tr">
<th id="S4.T1.6.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">LIF</th>
<td id="S4.T1.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T1.3.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.3.1.1.1.1.1" class="ltx_tr">
<td id="S4.T1.3.1.1.1.1.1.1" class="ltx_td ltx_align_center">0.77<math id="S4.T1.3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.3.1.1.1.1.1.1.m1.1a"><mo id="S4.T1.3.1.1.1.1.1.1.m1.1.1" xref="S4.T1.3.1.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.3.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.1.1.1.1.1.1.m1.1d">±</annotation></semantics></math>0.11,</td>
</tr>
<tr id="S4.T1.3.1.1.1.1.2" class="ltx_tr">
<td id="S4.T1.3.1.1.1.1.2.1" class="ltx_td ltx_align_center">0.93</td>
</tr>
</table>
</td>
<td id="S4.T1.4.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T1.4.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.4.2.2.2.1.1" class="ltx_tr">
<td id="S4.T1.4.2.2.2.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T1.4.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">0.74</span><math id="S4.T1.4.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.4.2.2.2.1.1.1.m1.1a"><mo id="S4.T1.4.2.2.2.1.1.1.m1.1.1" xref="S4.T1.4.2.2.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.2.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.4.2.2.2.1.1.1.m1.1.1.cmml" xref="S4.T1.4.2.2.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.2.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.2.2.2.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T1.4.2.2.2.1.1.1.2" class="ltx_text ltx_font_bold">0.06,</span>
</td>
</tr>
<tr id="S4.T1.4.2.2.2.1.2" class="ltx_tr">
<td id="S4.T1.4.2.2.2.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T1.4.2.2.2.1.2.1.1" class="ltx_text ltx_font_bold">0.79</span></td>
</tr>
</table>
</td>
<td id="S4.T1.5.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T1.5.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.5.3.3.3.1.1" class="ltx_tr">
<td id="S4.T1.5.3.3.3.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T1.5.3.3.3.1.1.1.1" class="ltx_text ltx_font_bold">0.73</span><math id="S4.T1.5.3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.5.3.3.3.1.1.1.m1.1a"><mo id="S4.T1.5.3.3.3.1.1.1.m1.1.1" xref="S4.T1.5.3.3.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.3.3.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.3.3.3.1.1.1.m1.1.1.cmml" xref="S4.T1.5.3.3.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.3.3.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.3.3.3.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T1.5.3.3.3.1.1.1.2" class="ltx_text ltx_font_bold">0.04,</span>
</td>
</tr>
<tr id="S4.T1.5.3.3.3.1.2" class="ltx_tr">
<td id="S4.T1.5.3.3.3.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T1.5.3.3.3.1.2.1.1" class="ltx_text ltx_font_bold">0.78</span></td>
</tr>
</table>
</td>
<td id="S4.T1.6.4.4.4" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T1.6.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.6.4.4.4.1.1" class="ltx_tr">
<td id="S4.T1.6.4.4.4.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T1.6.4.4.4.1.1.1.1" class="ltx_text ltx_font_bold">0.57<math id="S4.T1.6.4.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.6.4.4.4.1.1.1.1.m1.1a"><mo mathvariant="normal" id="S4.T1.6.4.4.4.1.1.1.1.m1.1.1" xref="S4.T1.6.4.4.4.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.4.4.4.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.6.4.4.4.1.1.1.1.m1.1.1.cmml" xref="S4.T1.6.4.4.4.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.4.4.4.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.4.4.4.1.1.1.1.m1.1d">±</annotation></semantics></math>0.02,</span></td>
</tr>
<tr id="S4.T1.6.4.4.4.1.2" class="ltx_tr">
<td id="S4.T1.6.4.4.4.1.2.1" class="ltx_td ltx_align_center">0.59</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T1.10.8.8" class="ltx_tr">
<th id="S4.T1.10.8.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">EIF</th>
<td id="S4.T1.7.5.5.1" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T1.7.5.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.7.5.5.1.1.1" class="ltx_tr">
<td id="S4.T1.7.5.5.1.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T1.7.5.5.1.1.1.1.1" class="ltx_text ltx_font_bold">0.80</span><math id="S4.T1.7.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.7.5.5.1.1.1.1.m1.1a"><mo id="S4.T1.7.5.5.1.1.1.1.m1.1.1" xref="S4.T1.7.5.5.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.5.5.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.7.5.5.1.1.1.1.m1.1.1.cmml" xref="S4.T1.7.5.5.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.5.5.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.5.5.1.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T1.7.5.5.1.1.1.1.2" class="ltx_text ltx_font_bold">0.12,</span>
</td>
</tr>
<tr id="S4.T1.7.5.5.1.1.2" class="ltx_tr">
<td id="S4.T1.7.5.5.1.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T1.7.5.5.1.1.2.1.1" class="ltx_text ltx_font_bold">0.94</span></td>
</tr>
</table>
</td>
<td id="S4.T1.8.6.6.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T1.8.6.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.8.6.6.2.1.1" class="ltx_tr">
<td id="S4.T1.8.6.6.2.1.1.1" class="ltx_td ltx_align_center">0.64<math id="S4.T1.8.6.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.8.6.6.2.1.1.1.m1.1a"><mo id="S4.T1.8.6.6.2.1.1.1.m1.1.1" xref="S4.T1.8.6.6.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.6.6.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.8.6.6.2.1.1.1.m1.1.1.cmml" xref="S4.T1.8.6.6.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.6.6.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.6.6.2.1.1.1.m1.1d">±</annotation></semantics></math>0.07,</td>
</tr>
<tr id="S4.T1.8.6.6.2.1.2" class="ltx_tr">
<td id="S4.T1.8.6.6.2.1.2.1" class="ltx_td ltx_align_center">0.71</td>
</tr>
</table>
</td>
<td id="S4.T1.9.7.7.3" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T1.9.7.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.9.7.7.3.1.1" class="ltx_tr">
<td id="S4.T1.9.7.7.3.1.1.1" class="ltx_td ltx_align_center">0.65<math id="S4.T1.9.7.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.9.7.7.3.1.1.1.m1.1a"><mo id="S4.T1.9.7.7.3.1.1.1.m1.1.1" xref="S4.T1.9.7.7.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.7.7.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.9.7.7.3.1.1.1.m1.1.1.cmml" xref="S4.T1.9.7.7.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.7.7.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.7.7.3.1.1.1.m1.1d">±</annotation></semantics></math>0.04,</td>
</tr>
<tr id="S4.T1.9.7.7.3.1.2" class="ltx_tr">
<td id="S4.T1.9.7.7.3.1.2.1" class="ltx_td ltx_align_center">0.71</td>
</tr>
</table>
</td>
<td id="S4.T1.10.8.8.4" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T1.10.8.8.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.10.8.8.4.1.1" class="ltx_tr">
<td id="S4.T1.10.8.8.4.1.1.1" class="ltx_td ltx_align_center">0.55<math id="S4.T1.10.8.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.10.8.8.4.1.1.1.m1.1a"><mo id="S4.T1.10.8.8.4.1.1.1.m1.1.1" xref="S4.T1.10.8.8.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.8.8.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.10.8.8.4.1.1.1.m1.1.1.cmml" xref="S4.T1.10.8.8.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.8.8.4.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.8.8.4.1.1.1.m1.1d">±</annotation></semantics></math>0.04,</td>
</tr>
<tr id="S4.T1.10.8.8.4.1.2" class="ltx_tr">
<td id="S4.T1.10.8.8.4.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T1.10.8.8.4.1.2.1.1" class="ltx_text ltx_font_bold">0.61</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T1.14.12.12" class="ltx_tr">
<th id="S4.T1.14.12.12.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">QIF</th>
<td id="S4.T1.11.9.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T1.11.9.9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.11.9.9.1.1.1" class="ltx_tr">
<td id="S4.T1.11.9.9.1.1.1.1" class="ltx_td ltx_align_center">0.57<math id="S4.T1.11.9.9.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.11.9.9.1.1.1.1.m1.1a"><mo id="S4.T1.11.9.9.1.1.1.1.m1.1.1" xref="S4.T1.11.9.9.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.9.9.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.11.9.9.1.1.1.1.m1.1.1.cmml" xref="S4.T1.11.9.9.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.9.9.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.9.9.1.1.1.1.m1.1d">±</annotation></semantics></math>0.03,</td>
</tr>
<tr id="S4.T1.11.9.9.1.1.2" class="ltx_tr">
<td id="S4.T1.11.9.9.1.1.2.1" class="ltx_td ltx_align_center">0.61</td>
</tr>
</table>
</td>
<td id="S4.T1.12.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T1.12.10.10.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.12.10.10.2.1.1" class="ltx_tr">
<td id="S4.T1.12.10.10.2.1.1.1" class="ltx_td ltx_align_center">0.54<math id="S4.T1.12.10.10.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.12.10.10.2.1.1.1.m1.1a"><mo id="S4.T1.12.10.10.2.1.1.1.m1.1.1" xref="S4.T1.12.10.10.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.10.10.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.12.10.10.2.1.1.1.m1.1.1.cmml" xref="S4.T1.12.10.10.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.10.10.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.10.10.2.1.1.1.m1.1d">±</annotation></semantics></math>0.03,</td>
</tr>
<tr id="S4.T1.12.10.10.2.1.2" class="ltx_tr">
<td id="S4.T1.12.10.10.2.1.2.1" class="ltx_td ltx_align_center">0.58</td>
</tr>
</table>
</td>
<td id="S4.T1.13.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T1.13.11.11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.13.11.11.3.1.1" class="ltx_tr">
<td id="S4.T1.13.11.11.3.1.1.1" class="ltx_td ltx_align_center">0.51<math id="S4.T1.13.11.11.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.13.11.11.3.1.1.1.m1.1a"><mo id="S4.T1.13.11.11.3.1.1.1.m1.1.1" xref="S4.T1.13.11.11.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.11.11.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.13.11.11.3.1.1.1.m1.1.1.cmml" xref="S4.T1.13.11.11.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.11.11.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.11.11.3.1.1.1.m1.1d">±</annotation></semantics></math>0.02,</td>
</tr>
<tr id="S4.T1.13.11.11.3.1.2" class="ltx_tr">
<td id="S4.T1.13.11.11.3.1.2.1" class="ltx_td ltx_align_center">0.55</td>
</tr>
</table>
</td>
<td id="S4.T1.14.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T1.14.12.12.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.14.12.12.4.1.1" class="ltx_tr">
<td id="S4.T1.14.12.12.4.1.1.1" class="ltx_td ltx_align_center">0.52<math id="S4.T1.14.12.12.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.14.12.12.4.1.1.1.m1.1a"><mo id="S4.T1.14.12.12.4.1.1.1.m1.1.1" xref="S4.T1.14.12.12.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.12.12.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.14.12.12.4.1.1.1.m1.1.1.cmml" xref="S4.T1.14.12.12.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.12.12.4.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.12.12.4.1.1.1.m1.1d">±</annotation></semantics></math>0.02,</td>
</tr>
<tr id="S4.T1.14.12.12.4.1.2" class="ltx_tr">
<td id="S4.T1.14.12.12.4.1.2.1" class="ltx_td ltx_align_center">0.55</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Table of results on the DVS Gestures dataset. In each cell, the mean accuracy <math id="S4.T2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.2.m1.1b"><mo id="S4.T2.2.m1.1.1" xref="S4.T2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.m1.1c"><csymbol cd="latexml" id="S4.T2.2.m1.1.1.cmml" xref="S4.T2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.m1.1e">±</annotation></semantics></math> the standard deviation values are followed by the best accuracy found (after the comma). Values are rounded up to the closest second decimal value. In the table, HC stands for Hand Clapping, RHW for Right Hand Wave, RACW for Right Arm Clockwise, AG for Air Guitar, RACCW for Right Arm Counter Clockwise, AR for Arm Roll, LACW for Left Arm Clockwise and AD for Air Drums.</figcaption>
<div id="S4.T2.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:196.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(60.3pt,-27.4pt) scale(1.38493529562212,1.38493529562212) ;">
<table id="S4.T2.14.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.14.12.13.1" class="ltx_tr">
<th id="S4.T2.14.12.13.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Neuron Model</th>
<th id="S4.T2.14.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">HC vs RHW</th>
<th id="S4.T2.14.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RACW vs AG</th>
<th id="S4.T2.14.12.13.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RHCW vs AR</th>
<th id="S4.T2.14.12.13.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">LACW vs AD</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.6.4.4" class="ltx_tr">
<th id="S4.T2.6.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">LIF</th>
<td id="S4.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T2.3.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.1.1.1.1.1" class="ltx_tr">
<td id="S4.T2.3.1.1.1.1.1.1" class="ltx_td ltx_align_center">0.53<math id="S4.T2.3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.3.1.1.1.1.1.1.m1.1a"><mo id="S4.T2.3.1.1.1.1.1.1.m1.1.1" xref="S4.T2.3.1.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.3.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.3.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.1.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.1.1.1.1.1.1.m1.1d">±</annotation></semantics></math>0.06,</td>
</tr>
<tr id="S4.T2.3.1.1.1.1.2" class="ltx_tr">
<td id="S4.T2.3.1.1.1.1.2.1" class="ltx_td ltx_align_center">0.60</td>
</tr>
</table>
</td>
<td id="S4.T2.4.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T2.4.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.4.2.2.2.1.1" class="ltx_tr">
<td id="S4.T2.4.2.2.2.1.1.1" class="ltx_td ltx_align_center">0.50<math id="S4.T2.4.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.4.2.2.2.1.1.1.m1.1a"><mo id="S4.T2.4.2.2.2.1.1.1.m1.1.1" xref="S4.T2.4.2.2.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.2.2.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.4.2.2.2.1.1.1.m1.1.1.cmml" xref="S4.T2.4.2.2.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.2.2.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.2.2.2.1.1.1.m1.1d">±</annotation></semantics></math>0.05,</td>
</tr>
<tr id="S4.T2.4.2.2.2.1.2" class="ltx_tr">
<td id="S4.T2.4.2.2.2.1.2.1" class="ltx_td ltx_align_center">0.56</td>
</tr>
</table>
</td>
<td id="S4.T2.5.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T2.5.3.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.5.3.3.3.1.1" class="ltx_tr">
<td id="S4.T2.5.3.3.3.1.1.1" class="ltx_td ltx_align_center">0.54<math id="S4.T2.5.3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.5.3.3.3.1.1.1.m1.1a"><mo id="S4.T2.5.3.3.3.1.1.1.m1.1.1" xref="S4.T2.5.3.3.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.3.3.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.5.3.3.3.1.1.1.m1.1.1.cmml" xref="S4.T2.5.3.3.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.3.3.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.3.3.3.1.1.1.m1.1d">±</annotation></semantics></math>0.13,</td>
</tr>
<tr id="S4.T2.5.3.3.3.1.2" class="ltx_tr">
<td id="S4.T2.5.3.3.3.1.2.1" class="ltx_td ltx_align_center">0.66</td>
</tr>
</table>
</td>
<td id="S4.T2.6.4.4.4" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T2.6.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.6.4.4.4.1.1" class="ltx_tr">
<td id="S4.T2.6.4.4.4.1.1.1" class="ltx_td ltx_align_center">0.52<math id="S4.T2.6.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.6.4.4.4.1.1.1.m1.1a"><mo id="S4.T2.6.4.4.4.1.1.1.m1.1.1" xref="S4.T2.6.4.4.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.4.4.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.6.4.4.4.1.1.1.m1.1.1.cmml" xref="S4.T2.6.4.4.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.4.4.4.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.4.4.4.1.1.1.m1.1d">±</annotation></semantics></math>0.09,</td>
</tr>
<tr id="S4.T2.6.4.4.4.1.2" class="ltx_tr">
<td id="S4.T2.6.4.4.4.1.2.1" class="ltx_td ltx_align_center">0.69</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T2.10.8.8" class="ltx_tr">
<th id="S4.T2.10.8.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">EIF</th>
<td id="S4.T2.7.5.5.1" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T2.7.5.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.7.5.5.1.1.1" class="ltx_tr">
<td id="S4.T2.7.5.5.1.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T2.7.5.5.1.1.1.1.1" class="ltx_text ltx_font_bold">0.58</span><math id="S4.T2.7.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.7.5.5.1.1.1.1.m1.1a"><mo id="S4.T2.7.5.5.1.1.1.1.m1.1.1" xref="S4.T2.7.5.5.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.5.5.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.7.5.5.1.1.1.1.m1.1.1.cmml" xref="S4.T2.7.5.5.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.5.5.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.5.5.1.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T2.7.5.5.1.1.1.1.2" class="ltx_text ltx_font_bold">0.12,</span>
</td>
</tr>
<tr id="S4.T2.7.5.5.1.1.2" class="ltx_tr">
<td id="S4.T2.7.5.5.1.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T2.7.5.5.1.1.2.1.1" class="ltx_text ltx_font_bold">0.77</span></td>
</tr>
</table>
</td>
<td id="S4.T2.8.6.6.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T2.8.6.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.8.6.6.2.1.1" class="ltx_tr">
<td id="S4.T2.8.6.6.2.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T2.8.6.6.2.1.1.1.1" class="ltx_text ltx_font_bold">0.50</span><math id="S4.T2.8.6.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.8.6.6.2.1.1.1.m1.1a"><mo id="S4.T2.8.6.6.2.1.1.1.m1.1.1" xref="S4.T2.8.6.6.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.6.6.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.8.6.6.2.1.1.1.m1.1.1.cmml" xref="S4.T2.8.6.6.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.6.6.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.8.6.6.2.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T2.8.6.6.2.1.1.1.2" class="ltx_text ltx_font_bold">0.04,</span>
</td>
</tr>
<tr id="S4.T2.8.6.6.2.1.2" class="ltx_tr">
<td id="S4.T2.8.6.6.2.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T2.8.6.6.2.1.2.1.1" class="ltx_text ltx_font_bold">0.58</span></td>
</tr>
</table>
</td>
<td id="S4.T2.9.7.7.3" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T2.9.7.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.9.7.7.3.1.1" class="ltx_tr">
<td id="S4.T2.9.7.7.3.1.1.1" class="ltx_td ltx_align_center">0.53<math id="S4.T2.9.7.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.9.7.7.3.1.1.1.m1.1a"><mo id="S4.T2.9.7.7.3.1.1.1.m1.1.1" xref="S4.T2.9.7.7.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.7.7.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.9.7.7.3.1.1.1.m1.1.1.cmml" xref="S4.T2.9.7.7.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.7.7.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.9.7.7.3.1.1.1.m1.1d">±</annotation></semantics></math>0.11,</td>
</tr>
<tr id="S4.T2.9.7.7.3.1.2" class="ltx_tr">
<td id="S4.T2.9.7.7.3.1.2.1" class="ltx_td ltx_align_center">0.66</td>
</tr>
</table>
</td>
<td id="S4.T2.10.8.8.4" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T2.10.8.8.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.10.8.8.4.1.1" class="ltx_tr">
<td id="S4.T2.10.8.8.4.1.1.1" class="ltx_td ltx_align_center">0.46<math id="S4.T2.10.8.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.10.8.8.4.1.1.1.m1.1a"><mo id="S4.T2.10.8.8.4.1.1.1.m1.1.1" xref="S4.T2.10.8.8.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.10.8.8.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.10.8.8.4.1.1.1.m1.1.1.cmml" xref="S4.T2.10.8.8.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.8.8.4.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.10.8.8.4.1.1.1.m1.1d">±</annotation></semantics></math>0.05,</td>
</tr>
<tr id="S4.T2.10.8.8.4.1.2" class="ltx_tr">
<td id="S4.T2.10.8.8.4.1.2.1" class="ltx_td ltx_align_center">0.52</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T2.14.12.12" class="ltx_tr">
<th id="S4.T2.14.12.12.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t">QIF</th>
<td id="S4.T2.11.9.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T2.11.9.9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.11.9.9.1.1.1" class="ltx_tr">
<td id="S4.T2.11.9.9.1.1.1.1" class="ltx_td ltx_align_center">0.57<math id="S4.T2.11.9.9.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.11.9.9.1.1.1.1.m1.1a"><mo id="S4.T2.11.9.9.1.1.1.1.m1.1.1" xref="S4.T2.11.9.9.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.11.9.9.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.11.9.9.1.1.1.1.m1.1.1.cmml" xref="S4.T2.11.9.9.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.9.9.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.11.9.9.1.1.1.1.m1.1d">±</annotation></semantics></math>0.10,</td>
</tr>
<tr id="S4.T2.11.9.9.1.1.2" class="ltx_tr">
<td id="S4.T2.11.9.9.1.1.2.1" class="ltx_td ltx_align_center">0.71</td>
</tr>
</table>
</td>
<td id="S4.T2.12.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T2.12.10.10.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.12.10.10.2.1.1" class="ltx_tr">
<td id="S4.T2.12.10.10.2.1.1.1" class="ltx_td ltx_align_center">0.48<math id="S4.T2.12.10.10.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.12.10.10.2.1.1.1.m1.1a"><mo id="S4.T2.12.10.10.2.1.1.1.m1.1.1" xref="S4.T2.12.10.10.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.12.10.10.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.12.10.10.2.1.1.1.m1.1.1.cmml" xref="S4.T2.12.10.10.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.10.10.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.12.10.10.2.1.1.1.m1.1d">±</annotation></semantics></math>0.04,</td>
</tr>
<tr id="S4.T2.12.10.10.2.1.2" class="ltx_tr">
<td id="S4.T2.12.10.10.2.1.2.1" class="ltx_td ltx_align_center">0.52</td>
</tr>
</table>
</td>
<td id="S4.T2.13.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T2.13.11.11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.13.11.11.3.1.1" class="ltx_tr">
<td id="S4.T2.13.11.11.3.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T2.13.11.11.3.1.1.1.1" class="ltx_text ltx_font_bold">0.62</span><math id="S4.T2.13.11.11.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.13.11.11.3.1.1.1.m1.1a"><mo id="S4.T2.13.11.11.3.1.1.1.m1.1.1" xref="S4.T2.13.11.11.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.13.11.11.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.13.11.11.3.1.1.1.m1.1.1.cmml" xref="S4.T2.13.11.11.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.11.11.3.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.13.11.11.3.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T2.13.11.11.3.1.1.1.2" class="ltx_text ltx_font_bold">0.06,</span>
</td>
</tr>
<tr id="S4.T2.13.11.11.3.1.2" class="ltx_tr">
<td id="S4.T2.13.11.11.3.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T2.13.11.11.3.1.2.1.1" class="ltx_text ltx_font_bold">0.67</span></td>
</tr>
</table>
</td>
<td id="S4.T2.14.12.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T2.14.12.12.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.14.12.12.4.1.1" class="ltx_tr">
<td id="S4.T2.14.12.12.4.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T2.14.12.12.4.1.1.1.1" class="ltx_text ltx_font_bold">0.53</span><math id="S4.T2.14.12.12.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.14.12.12.4.1.1.1.m1.1a"><mo id="S4.T2.14.12.12.4.1.1.1.m1.1.1" xref="S4.T2.14.12.12.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.14.12.12.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.14.12.12.4.1.1.1.m1.1.1.cmml" xref="S4.T2.14.12.12.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.12.12.4.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T2.14.12.12.4.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T2.14.12.12.4.1.1.1.2" class="ltx_text ltx_font_bold">0.09,</span>
</td>
</tr>
<tr id="S4.T2.14.12.12.4.1.2" class="ltx_tr">
<td id="S4.T2.14.12.12.4.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T2.14.12.12.4.1.2.1.1" class="ltx_text ltx_font_bold">0.75</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">By examining the results on the N-MNIST-based tasks in Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Same Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the LIF neuron model is found to perform better than the other two on average. Indeed, the EIF has higher average accuracy only on the 0 vs 1 task, whereas the QIF model fails to achieve accuracy levels high enough to match any of the other two counterparts.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p">Considering the results reported in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Same Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the situation differs slightly. The performance of both the LIF and the EIF neuron models, on average, decreases drastically, whereas the QIF maintains similar levels of accuracy as in the N-MNIST case. Nevertheless, both the EIF and QIF demonstrate superior classification abilities throughout and their top accuracy levels often surpass those of the LIF model.
These trends in the accuracy levels highlight two main aspects. Firstly, the complexity of the N-MNIST data is lower than that of the DVS Gestures dataset. Indeed, in both cases, the very same neural network architecture and neuron models were employed, yet the accuracy in the DVS Gestures is on average considerably lower, hence highlighting the greater difficulty of the task. Data samples in the DVS Gestures dataset arguably have richer visual and temporal features which render the learning more difficult when compared to the N-MNIST. Secondly, the richer temporal diversity of the features might be better represented by means of neurons with richer voltage dynamics, such as the QIF and EIF. As reported by the experiments, in fact, these two are steadily better than the LIF models and even though in some instances one performs more poorly, the other still attains higher accuracy, possibly as a result of a better affinity to the temporal dynamics found in that particular task.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Optimized Hyper-Parameters Training</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">As a second set of experiments, we employ the optimization system outlined in Section  <a href="#S3.SS5" title="3.5 Hyper-parameter Optimization ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a> to obtain a set of hyper-parameters that is heuristically optimal for a specific scenario. The optimization is carried out on the "0 vs 1" and on the "HC vs RHW" tasks for each neuron model individually. We allow a total of 24 optimization iterations for each neuron and task, to not favor any experiment over the others. Results are reported in Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Optimized Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Once again, after obtaining the optimized hyper-parameters, we train and evaluate each model a total of 11 times to increase the robustness of the results.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Table of results using optimized hyper-parameters. In each cell, the mean accuracy <math id="S4.T3.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.2.m1.1b"><mo id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><csymbol cd="latexml" id="S4.T3.2.m1.1.1.cmml" xref="S4.T3.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.m1.1e">±</annotation></semantics></math> the standard deviation values are followed by the best accuracy found (after the comma). Values are rounded up to the closest second decimal value. Optimization and evaluation is performed on one representative task per dataset only.</figcaption>
<table id="S4.T3.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.8.7.1" class="ltx_tr">
<th id="S4.T3.8.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Neuron Model</th>
<th id="S4.T3.8.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">0 vs 1</th>
<th id="S4.T3.8.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">HC vs RHW</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.4.2" class="ltx_tr">
<th id="S4.T3.4.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">LIF</th>
<td id="S4.T3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.3.1.1.1.1" class="ltx_tr">
<td id="S4.T3.3.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="S4.T3.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">0.95<math id="S4.T3.3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.3.1.1.1.1.1.1.m1.1a"><mo mathvariant="normal" id="S4.T3.3.1.1.1.1.1.1.m1.1.1" xref="S4.T3.3.1.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.3.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.1.1.1.1.1.1.m1.1d">±</annotation></semantics></math>0.02,</span></td>
</tr>
<tr id="S4.T3.3.1.1.1.2" class="ltx_tr">
<td id="S4.T3.3.1.1.1.2.1" class="ltx_td ltx_align_center">0.982</td>
</tr>
</table>
</td>
<td id="S4.T3.4.2.2" class="ltx_td ltx_align_center ltx_border_tt">
<table id="S4.T3.4.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.4.2.2.1.1" class="ltx_tr">
<td id="S4.T3.4.2.2.1.1.1" class="ltx_td ltx_align_center">0.53<math id="S4.T3.4.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.4.2.2.1.1.1.m1.1a"><mo id="S4.T3.4.2.2.1.1.1.m1.1.1" xref="S4.T3.4.2.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.4.2.2.1.1.1.m1.1.1.cmml" xref="S4.T3.4.2.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.2.2.1.1.1.m1.1d">±</annotation></semantics></math>0.05,</td>
</tr>
<tr id="S4.T3.4.2.2.1.2" class="ltx_tr">
<td id="S4.T3.4.2.2.1.2.1" class="ltx_td ltx_align_center">0.625</td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.6.4" class="ltx_tr">
<th id="S4.T3.6.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">EIF</th>
<td id="S4.T3.5.3.1" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T3.5.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.5.3.1.1.1" class="ltx_tr">
<td id="S4.T3.5.3.1.1.1.1" class="ltx_td ltx_align_center">0.74<math id="S4.T3.5.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.5.3.1.1.1.1.m1.1a"><mo id="S4.T3.5.3.1.1.1.1.m1.1.1" xref="S4.T3.5.3.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.5.3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.5.3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.3.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.3.1.1.1.1.m1.1d">±</annotation></semantics></math>0.15,</td>
</tr>
<tr id="S4.T3.5.3.1.1.2" class="ltx_tr">
<td id="S4.T3.5.3.1.1.2.1" class="ltx_td ltx_align_center">0.93</td>
</tr>
</table>
</td>
<td id="S4.T3.6.4.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="S4.T3.6.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.6.4.2.1.1" class="ltx_tr">
<td id="S4.T3.6.4.2.1.1.1" class="ltx_td ltx_align_center">
<span id="S4.T3.6.4.2.1.1.1.1" class="ltx_text ltx_font_bold">0.57</span><math id="S4.T3.6.4.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.6.4.2.1.1.1.m1.1a"><mo id="S4.T3.6.4.2.1.1.1.m1.1.1" xref="S4.T3.6.4.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.4.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.6.4.2.1.1.1.m1.1.1.cmml" xref="S4.T3.6.4.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.4.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.4.2.1.1.1.m1.1d">±</annotation></semantics></math><span id="S4.T3.6.4.2.1.1.1.2" class="ltx_text ltx_font_bold">0.11,</span>
</td>
</tr>
<tr id="S4.T3.6.4.2.1.2" class="ltx_tr">
<td id="S4.T3.6.4.2.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T3.6.4.2.1.2.1.1" class="ltx_text ltx_font_bold">0.67</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S4.T3.8.6" class="ltx_tr">
<th id="S4.T3.8.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">QIF</th>
<td id="S4.T3.7.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T3.7.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.5.1.1.1" class="ltx_tr">
<td id="S4.T3.7.5.1.1.1.1" class="ltx_td ltx_align_center">0.90<math id="S4.T3.7.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.7.5.1.1.1.1.m1.1a"><mo id="S4.T3.7.5.1.1.1.1.m1.1.1" xref="S4.T3.7.5.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.5.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.7.5.1.1.1.1.m1.1.1.cmml" xref="S4.T3.7.5.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.5.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.5.1.1.1.1.m1.1d">±</annotation></semantics></math>0.05,</td>
</tr>
<tr id="S4.T3.7.5.1.1.2" class="ltx_tr">
<td id="S4.T3.7.5.1.1.2.1" class="ltx_td ltx_align_center"><span id="S4.T3.7.5.1.1.2.1.1" class="ltx_text ltx_font_bold">0.985</span></td>
</tr>
</table>
</td>
<td id="S4.T3.8.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<table id="S4.T3.8.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.8.6.2.1.1" class="ltx_tr">
<td id="S4.T3.8.6.2.1.1.1" class="ltx_td ltx_align_center">0.55<math id="S4.T3.8.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.8.6.2.1.1.1.m1.1a"><mo id="S4.T3.8.6.2.1.1.1.m1.1.1" xref="S4.T3.8.6.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.6.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.8.6.2.1.1.1.m1.1.1.cmml" xref="S4.T3.8.6.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.6.2.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.6.2.1.1.1.m1.1d">±</annotation></semantics></math>0.05,</td>
</tr>
<tr id="S4.T3.8.6.2.1.2" class="ltx_tr">
<td id="S4.T3.8.6.2.1.2.1" class="ltx_td ltx_align_center">0.625</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<br class="ltx_break">
<br class="ltx_break">
<p id="S4.SS2.p2.1" class="ltx_p">Since the optimization is task-specific, we only evaluate our models on the two representative tasks they were optimized on. In the case of the "0 vs 1" task based on the N-MNIST, overall, the accuracy levels drastically increase. The LIF model accuracy grows by nearly 20 percentage points on average; however, the most striking increase is the accuracy of the QIF model, which gains 33 percentage points on average and 37.5 in the best case. This not only highlights the sensitivity of neuron models to their hyper-parameters, but also confirms that neurons with more complex dynamics can perform just as well as simpler ones.

<br class="ltx_break">In the case of the "HC vs RHW" task, instead, we see a slightly different trend. In the first place, the results are surprisingly worse than those obtained through hand-picked parameters. We hypothesize that this is because the optimization system required more iterations to find a good set of hyper-parameters. As stated above, we allowed the same number of optimization iterations as in the case of the N-MNIST dataset. However, given the higher complexity of the features present in the DVS Gestures dataset, it might have been necessary to allow more. Secondly, although still struggling to achieve higher accuracy levels, the SNNs employing QIF and EIF averagely outperform those with the LIF. This confirms the results obtained using the same hyper-parameters and strengthen the hypothesis that richer dynamics can be beneficial when employed on data with a richer set of temporal features.

<br class="ltx_break">
<br class="ltx_break">Another point worth considering is the variability of the results obtained. Spanning from the N-MNIST-based tasks to the Gestures-based ones, the different neuron models demonstrate accuracy levels with a standard deviation of up to 15 percentage points. We hypothesize that this effect is caused by the order in which data is presented to the system in relation to the STDP learning rule which, as reported at the beginning of this section, is sensitive to such order. Apart from this, we further observe that the EIF model has higher fluctuations on average, thus demonstrating more sensitivity to this effect.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 5 </span>Discussion</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Implications of Using Different Neuron Models</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The usage of spiking neuron models has some inherent implications on the machine learning pipeline from the implementation and the theoretical points of view.

<br class="ltx_break">Concerning the implementation, spiking neuron come with a whole set of hyper-parameters to tune. Considering the LIF, the simplest version requires a single parameter (the time costant or a leakage term), but other implementations might include up to 5 different parameters, such as the refractory period or the time-step size. If we switch to the QIF or the EIF, there are at least two new and non-optional parameters to consider (see <a href="#S2.SS1" title="2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>).

<br class="ltx_break">Determining a good set of hyper-parameters is a non-trivial task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. Although in the NM field a lot of inspiration is taken from the human brain, it is not possible to simply assume that the same parameters that work in such a complex system would still be applicable in a simplification such as an SNN. We hence need to tweak parameters for our need or, alternatively, to define a parameter optimization strategy that does that heuristically in an automated way. However, also the latter solution often requires to make guesses about the domain in which parameters can vary and it requires a long time to compute. Furthermore, hyper-parameters can be correlated in some way, thus making both the hand-tuning and the automated optimization process more difficult.
As a result, from an implementation point of view, using neuron models that require more hyper-parameters can significantly increase the usage complexity.

<br class="ltx_break"></p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2207.04881/assets/x7.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="415" height="311" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2207.04881/assets/x8.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="415" height="311" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Example of membrane potential dynamics of the spiking neuron models. In both figures, the y-axis represents the variation of the membrane potential <math id="S5.F5.4.m1.1" class="ltx_Math" alttext="du" display="inline"><semantics id="S5.F5.4.m1.1b"><mrow id="S5.F5.4.m1.1.1" xref="S5.F5.4.m1.1.1.cmml"><mi id="S5.F5.4.m1.1.1.2" xref="S5.F5.4.m1.1.1.2.cmml">d</mi><mo id="S5.F5.4.m1.1.1.1" xref="S5.F5.4.m1.1.1.1.cmml">⁢</mo><mi id="S5.F5.4.m1.1.1.3" xref="S5.F5.4.m1.1.1.3.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.4.m1.1c"><apply id="S5.F5.4.m1.1.1.cmml" xref="S5.F5.4.m1.1.1"><times id="S5.F5.4.m1.1.1.1.cmml" xref="S5.F5.4.m1.1.1.1"></times><ci id="S5.F5.4.m1.1.1.2.cmml" xref="S5.F5.4.m1.1.1.2">𝑑</ci><ci id="S5.F5.4.m1.1.1.3.cmml" xref="S5.F5.4.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.4.m1.1d">du</annotation><annotation encoding="application/x-llamapun" id="S5.F5.4.m1.1e">italic_d italic_u</annotation></semantics></math>, while the x-axis represents the value of the membrane potential itself <math id="S5.F5.5.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S5.F5.5.m2.1b"><mi id="S5.F5.5.m2.1.1" xref="S5.F5.5.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S5.F5.5.m2.1c"><ci id="S5.F5.5.m2.1.1.cmml" xref="S5.F5.5.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.5.m2.1d">u</annotation><annotation encoding="application/x-llamapun" id="S5.F5.5.m2.1e">italic_u</annotation></semantics></math>. Figure  <a href="#S5.F5.sf1" title="5a ‣ Figure 5 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5a</span></a> compares the three spiking neurons, whereas Figure  <a href="#S5.F5.sf2" title="5b ‣ Figure 5 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5b</span></a> is an example of how varying the sharpness parameter <math id="S5.F5.6.m3.1" class="ltx_Math" alttext="\Delta_{T}" display="inline"><semantics id="S5.F5.6.m3.1b"><msub id="S5.F5.6.m3.1.1" xref="S5.F5.6.m3.1.1.cmml"><mi mathvariant="normal" id="S5.F5.6.m3.1.1.2" xref="S5.F5.6.m3.1.1.2.cmml">Δ</mi><mi id="S5.F5.6.m3.1.1.3" xref="S5.F5.6.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F5.6.m3.1c"><apply id="S5.F5.6.m3.1.1.cmml" xref="S5.F5.6.m3.1.1"><csymbol cd="ambiguous" id="S5.F5.6.m3.1.1.1.cmml" xref="S5.F5.6.m3.1.1">subscript</csymbol><ci id="S5.F5.6.m3.1.1.2.cmml" xref="S5.F5.6.m3.1.1.2">Δ</ci><ci id="S5.F5.6.m3.1.1.3.cmml" xref="S5.F5.6.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.6.m3.1d">\Delta_{T}</annotation><annotation encoding="application/x-llamapun" id="S5.F5.6.m3.1e">roman_Δ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math> can affect the dynamics of the EIF.</figcaption>
</figure>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="S5.F6.sf1" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="/html/2207.04881/assets/x9.png" id="S5.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="830" height="236" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="S5.F6.sf2" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="/html/2207.04881/assets/x10.png" id="S5.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="830" height="236" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="S5.F6.sf3" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="/html/2207.04881/assets/x11.png" id="S5.F6.sf3.g1" class="ltx_graphics ltx_img_landscape" width="830" height="238" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Example of Changing Hyper-Parameters in a LIF Neuron. The “Fast forgetting” neuron (smaller time constant <math id="S5.F6.2.m1.1" class="ltx_Math" alttext="\tau_{m}" display="inline"><semantics id="S5.F6.2.m1.1b"><msub id="S5.F6.2.m1.1.1" xref="S5.F6.2.m1.1.1.cmml"><mi id="S5.F6.2.m1.1.1.2" xref="S5.F6.2.m1.1.1.2.cmml">τ</mi><mi id="S5.F6.2.m1.1.1.3" xref="S5.F6.2.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.2.m1.1c"><apply id="S5.F6.2.m1.1.1.cmml" xref="S5.F6.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F6.2.m1.1.1.1.cmml" xref="S5.F6.2.m1.1.1">subscript</csymbol><ci id="S5.F6.2.m1.1.1.2.cmml" xref="S5.F6.2.m1.1.1.2">𝜏</ci><ci id="S5.F6.2.m1.1.1.3.cmml" xref="S5.F6.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.2.m1.1d">\tau_{m}</annotation><annotation encoding="application/x-llamapun" id="S5.F6.2.m1.1e">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>) (Figure <a href="#S5.F6.sf2" title="6b ‣ Figure 6 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6b</span></a>) can only spike twice in response to the input (Figure <a href="#S5.F6.sf1" title="6a ‣ Figure 6 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6a</span></a>). The “Slow forgetting” one (Figure <a href="#S5.F6.sf3" title="6c ‣ Figure 6 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6c</span></a>) can fire three times and maintains a higher membrane potential throughout. Note that the “Slow forgetting” neuron also fires earlier, i.e. it requires less (close) spikes to reach the threshold. Both the neurons have a refractory period of 2 ms.</figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.5" class="ltx_p">From a theoretical point of view, using different neurons or varying the parameters means to open to different non-linear dynamics and excitability patterns. Figure  <a href="#S5.F5" title="Figure 5 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Figure  <a href="#S5.F6" title="Figure 6 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> provide a visual understanding of these differences.
In the LIF, the membrane potential updates depend linearly on the previous state of the membrane potential itself. The EIF manifests a similar relationship up to certain values of membrane potential (<math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="\Theta_{rh}" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><msub id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">Θ</mi><mrow id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml"><mi id="S5.SS1.p2.1.m1.1.1.3.2" xref="S5.SS1.p2.1.m1.1.1.3.2.cmml">r</mi><mo id="S5.SS1.p2.1.m1.1.1.3.1" xref="S5.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.1.m1.1.1.3.3" xref="S5.SS1.p2.1.m1.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">Θ</ci><apply id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3"><times id="S5.SS1.p2.1.m1.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.3.1"></times><ci id="S5.SS1.p2.1.m1.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.3.2">𝑟</ci><ci id="S5.SS1.p2.1.m1.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\Theta_{rh}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">roman_Θ start_POSTSUBSCRIPT italic_r italic_h end_POSTSUBSCRIPT</annotation></semantics></math>), after which the relationship assumes a more non-linear (exponential) aspect. The QIF loses any linear relationship in favor of a quadratic one.
These dynamics play a role on the excitability (regions) of a neuron <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. For instance, an EIF with a smooth exponential term (blue line in Figure  <a href="#S5.F5.sf2" title="5b ‣ Figure 5 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5b</span></a>) will receive more mitigated updates throughout (slow-forgetting neuron), whereas an EIF with a sharp exponential term (orange line) will receive more negative updates up to the cutoff threshold <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="\Theta_{rh}" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><msub id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">Θ</mi><mrow id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml"><mi id="S5.SS1.p2.2.m2.1.1.3.2" xref="S5.SS1.p2.2.m2.1.1.3.2.cmml">r</mi><mo id="S5.SS1.p2.2.m2.1.1.3.1" xref="S5.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.2.m2.1.1.3.3" xref="S5.SS1.p2.2.m2.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.2">Θ</ci><apply id="S5.SS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3"><times id="S5.SS1.p2.2.m2.1.1.3.1.cmml" xref="S5.SS1.p2.2.m2.1.1.3.1"></times><ci id="S5.SS1.p2.2.m2.1.1.3.2.cmml" xref="S5.SS1.p2.2.m2.1.1.3.2">𝑟</ci><ci id="S5.SS1.p2.2.m2.1.1.3.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">\Theta_{rh}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">roman_Θ start_POSTSUBSCRIPT italic_r italic_h end_POSTSUBSCRIPT</annotation></semantics></math> and then very positive (<math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="+\infty" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><mo id="S5.SS1.p2.3.m3.1.1a" xref="S5.SS1.p2.3.m3.1.1.cmml">+</mo><mi mathvariant="normal" id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml">∞</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><plus id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"></plus><infinity id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">+\infty</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">+ ∞</annotation></semantics></math>) ones, thus immediately reaching the firing threshold <math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="V_{th}" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><msub id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml"><mi id="S5.SS1.p2.4.m4.1.1.2" xref="S5.SS1.p2.4.m4.1.1.2.cmml">V</mi><mrow id="S5.SS1.p2.4.m4.1.1.3" xref="S5.SS1.p2.4.m4.1.1.3.cmml"><mi id="S5.SS1.p2.4.m4.1.1.3.2" xref="S5.SS1.p2.4.m4.1.1.3.2.cmml">t</mi><mo id="S5.SS1.p2.4.m4.1.1.3.1" xref="S5.SS1.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.p2.4.m4.1.1.3.3" xref="S5.SS1.p2.4.m4.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><apply id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.4.m4.1.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.p2.4.m4.1.1.2.cmml" xref="S5.SS1.p2.4.m4.1.1.2">𝑉</ci><apply id="S5.SS1.p2.4.m4.1.1.3.cmml" xref="S5.SS1.p2.4.m4.1.1.3"><times id="S5.SS1.p2.4.m4.1.1.3.1.cmml" xref="S5.SS1.p2.4.m4.1.1.3.1"></times><ci id="S5.SS1.p2.4.m4.1.1.3.2.cmml" xref="S5.SS1.p2.4.m4.1.1.3.2">𝑡</ci><ci id="S5.SS1.p2.4.m4.1.1.3.3.cmml" xref="S5.SS1.p2.4.m4.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">V_{th}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.4.m4.1d">italic_V start_POSTSUBSCRIPT italic_t italic_h end_POSTSUBSCRIPT</annotation></semantics></math>. Hence, the second example would be a fast-forgetting neuron, but the cut-off threshold will act as an early firing threshold, as any subsequent update would bring the membrane potential up and above the actual firing threshold.
A similar example is reported in Figure  <a href="#S5.F6" title="Figure 6 ‣ 5.1 Implications of Using Different Neuron Models ‣ Section 5 Discussion ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, where a change in the time-constant <math id="S5.SS1.p2.5.m5.1" class="ltx_Math" alttext="\tau_{m}" display="inline"><semantics id="S5.SS1.p2.5.m5.1a"><msub id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml"><mi id="S5.SS1.p2.5.m5.1.1.2" xref="S5.SS1.p2.5.m5.1.1.2.cmml">τ</mi><mi id="S5.SS1.p2.5.m5.1.1.3" xref="S5.SS1.p2.5.m5.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><apply id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.p2.5.m5.1.1.2">𝜏</ci><ci id="S5.SS1.p2.5.m5.1.1.3.cmml" xref="S5.SS1.p2.5.m5.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">\tau_{m}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.5.m5.1d">italic_τ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> makes a LIF neuron forget faster or slower. This in turn has effects on the excitability of the neuron and its firing pattern.

<br class="ltx_break">
<br class="ltx_break">The different firing abilities discussed above need to be considered within the context where the neurons are placed. If we consider the case of a homogeneous SCNN that is trained on a dataset in which the temporal distribution of events is very similar for every sample, it might be pointless to consider having a wide range of excitability patters as more complex neurons have. Indeed, the increased amount of parameters would make it very difficult to find the right excitability that works well with that data. At the same time, they would likely come at a higher computational and power cost. Conversely, if the dataset is very diverse in terms of temporal distribution of events, it would arguably prove useful to have a broad range of excitability patterns to choose from. Therefore, an heterogeneous network of spiking neurons would likely be able to learn better or simply more features. In this context, employing more complex neurons with variable parameters can be significantly beneficial.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Temporal Features and Neuron Performance</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">In our experiments, we used a very simple homogeneous SCNN to perform a simple classification task on a simple subset of the N-MNIST and DVS Gesture datasets. The N-MNIST dataset, although natively event-based, is not a naturally dynamic dataset. The original data, the MNIST handwritten digits, are static images that do not contain temporal dynamical features. As such, the temporal features that are instead present in the N-MNIST are crafted. Furthermore, these dynamics are obtained by moving a DVS camera using the same sequence of movements with the same timing. Figure  <a href="#S2.F2.sf3" title="2c ‣ Figure 2 ‣ 2.1.2 Phenomenological Models ‣ 2.1 Neuron Models in the Literature ‣ Section 2 Background and Related Works ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2c</span></a> shows that, as a result, the distribution of events throughout each sample present in the dataset is roughly the same.
This means that the temporal features are not different from one another and are hence not discriminative of different classes of samples.
Indeed, as discussed in the previous paragraph, using a homogeneous SCNN was enough to achieve reasonably high accuracy levels, despite the lack of diversity in the dynamics of the embedded neurons.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p">Concerning the performance in such a homogeneous settings, in our consideration of three single-variable neuron models we found that all of them have the ability to perform well. The difference however is in the cost of using one neuron rather than the other. From our experiments, we found that when hand-tuning parameters, the LIF neuron achieved averagely high accuracy levels, with EIF neuron being better at times. Using a set of optimized hyper-parameters, we observed a considerable improvement in the overall classification accuracy with the QIF achieving a 98.5% accuracy in the best case, thus surpassing its counterparts. The very same QIF model performed rather poorly when using non-optimized parameters.
As mentioned in Section  <a href="#S4.SS2" title="4.2 Optimized Hyper-Parameters Training ‣ Section 4 Results ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, this highlights the fact that, despite the data displaying simple spatio-temporal features, more complex neurons are still able to perform well.
The cost for achieving such results can, however, become rather high.

<br class="ltx_break">
<br class="ltx_break">When employing Gestures data, the situations is slightly different. In this case, as depicted in Figure  <a href="#S3.F3" title="Figure 3 ‣ 3.2 Spiking Neurons Implementation ‣ Section 3 Methods ‣ Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, there is no recurring distribution of events across different classes. Instead, events are distributed throughout the whole time domain. Each class of gestures has a distribution of events that varies with respect to the others, even more because of the fact that different actions require a different time to be executed. Thus, the temporal features in this dataset are more important and diverse.
As a matter of fact, this is also shown by the results obtained using the same network as in the previous case. Here, although the performance gain is still modest, the EIF and QIF neurons steadily attain better classification accuracies than the LIF model. Since we used the same setting for all the experiments, this is likely traceable to the aforementioned differences in temporal features, which are now more diverse and complex than those in the N-MNIST dataset.

<br class="ltx_break"></p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Temporal Features and Depth of the Network</h3>

<div id="S5.SS3.p1" class="ltx_para ltx_noindent">
<p id="S5.SS3.p1.1" class="ltx_p">The matter of temporal variety in the features being better represented by more complex dynamics opens up further questions as to their use in SNNs. Indeed, if we consider a hierarchical NN, the deepest layers normally learn more abstract representations, whereas the early layers typically learn to distinguish simple patterns, such as edges or corners <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.
This is easily conceivable when thinking about spatial features. For example, when a set of lines is recognized in the early layers of a CNN, these could later be understood to be a square, and further down the network as a house. Although it can be more difficult to imagine, when we include the time dimension, similar scenarios can arise where features relate temporally other than spatially. It thus seems straightforward that the temporal relationships might vary in complexity in different stages of the network depending on the task at hand.
<br class="ltx_break">We have proved that the use of more complex neuron models improves the performance on more complex tasks at the level of one layer. When combining several of these layers in a hierarchical network more uses of their non-linear dynamics could arise, as they would combine several spatio-temporal features built up in previous stages to understand compound featural patterns.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">Section 6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">In this work, we have considered a simple unsupervised SCNN and analyzed the effect on the overall performance of changing the underlying neuron models. Because they were not previously present in the SpykeTorch framework, we implement the spiking neurons and make the code available. We firstly draw a set of 4 binary classification tasks using 4 couples of classes from the N-MNIST dataset on which we repeatedly train and evaluate our SCNN. Experimental results on these tasks show that all three neuron models can achieve top-level accuracies, albeit the more complex ones require more fine-tuning. On a second instance we consider the DVS Gestures dataset, which exposes a richer set of features from both the visual and temporal points of view. In this case, the EIF and QIF steadily outperform the LIF on all 4 tasks drawn from this dataset.
Collectively, our results show that accurately selecting the neuron model employed in an NM pipeline improves its performance, and that this selection should be driven by considering the complexity of the spatio-temporal features that the layer in the network will have to understand. Furthermore, it highlights that further research aimed at unveiling the role of the dynamics of neuron models in deep hierarchical learning would be highly beneficial to close the gap between conventional DL approaches and SNNs. Other future studies could consist of analysing further relationships between the neuron models and other components of the learning pipeline, such as the neural network architecture, and the learning rule.
</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by the US Air Force Office of Scientific Research under Grant for project FA8655-20-1-
7037. The contents were approved for public release under case AFRL-2022-2603 and they represent the views of only the
authors and does not represent any views or positions of the
Air Force Research Laboratory, US Department of Defense,
or US Government.
The authors declare that there is no conflict of interest.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">References</h2>

</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Catherine D. Schuman, Thomas E. Potok, Robert M. Patton, J. Douglas Birdwell,
Mark E. Dean, Garrett S. Rose, and James S. Plank.

</span>
<span class="ltx_bibblock">A survey of neuromorphic computing and neural networks in hardware.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Wulfram Gerstner, Werner M. Kistler, Richard Naud, and Liam Paninski.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Neuronal Dynamics</span>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2009.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Johannes Schemmel, Sebastian Billaudelle, Phillip Dauer, and Johannes Weis.

</span>
<span class="ltx_bibblock">Accelerated analog neuromorphic computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, abs/2003.11996, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Ben Varkey Benjamin, Peiran Gao, Emmett McQuinn, Swadesh Choudhary, Anand R.
Chandrasekaran, Jean-Marie Bussat, Rodrigo Alvarez-Icaza, John V. Arthur,
Paul A. Merolla, and Kwabena Boahen.

</span>
<span class="ltx_bibblock">Neurogrid: A mixed-analog-digital multichip system for large-scale
neural simulations.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 102(5):699–716, 2014.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao,
Sri Harsha Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain,
Yuyun Liao, Chit-Kwan Lin, Andrew Lines, Ruokun Liu, Deepak Mathaikutty,
Steven McCoy, Arnab Paul, Jonathan Tse, Guruguhanathan Venkataramanan,
Yi-Hsin Weng, Andreas Wild, Yoonseok Yang, and Hong Wang.

</span>
<span class="ltx_bibblock">Loihi: A neuromorphic manycore processor with on-chip learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">IEEE Micro</span>, 38(1):82–99, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Paul Merolla, John Arthur, Filipp Akopyan, Nabil Imam, Rajit Manohar, and
Dharmendra S. Modha.

</span>
<span class="ltx_bibblock">A digital neurosynaptic core using embedded crossbar memory with 45pj
per spike in 45nm.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">2011 IEEE Custom Integrated Circuits Conference (CICC)</span>,
pages 1–4, 2011.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Andrew S. Cassidy, Paul Merolla, John V. Arthur, Steve K. Esser, Bryan Jackson,
Rodrigo Alvarez-Icaza, Pallab Datta, Jun Sawada, Theodore M. Wong, Vitaly
Feldman, Arnon Amir, Daniel Ben-Dayan Rubin, Filipp Akopyan, Emmett McQuinn,
William P. Risk, and Dharmendra S. Modha.

</span>
<span class="ltx_bibblock">Cognitive computing building block: A versatile and efficient digital
neuron model for neurosynaptic cores.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">The 2013 International Joint Conference on Neural Networks
(IJCNN)</span>, pages 1–10, 2013.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Filipp Akopyan, Jun Sawada, Andrew Cassidy, Rodrigo Alvarez-Icaza, John Arthur,
Paul Merolla, Nabil Imam, Yutaka Nakamura, Pallab Datta, Gi-Joon Nam, Brian
Taba, Michael Beakes, Bernard Brezzo, Jente B. Kuang, Rajit Manohar,
William P. Risk, Bryan Jackson, and Dharmendra S. Modha.

</span>
<span class="ltx_bibblock">Truenorth: Design and tool flow of a 65 mw 1 million neuron
programmable neurosynaptic chip.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Computer-Aided Design of Integrated
Circuits and Systems</span>, 34(10):1537–1557, 2015.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Steve B. Furber, Francesco Galluppi, Steve Temple, and Luis A. Plana.

</span>
<span class="ltx_bibblock">The spinnaker project.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 102(5):652–665, 2014.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Garrick Orchard, E Paxon Frady, Daniel Ben Dayan Rubin, Sophia Sanborn,
Sumit Bam Shrestha, Friedrich T Sommer, and Mike Davies.

</span>
<span class="ltx_bibblock">Efficient neuromorphic signal processing with loihi 2.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">2021 IEEE Workshop on Signal Processing Systems (SiPS)</span>,
pages 254–259. IEEE, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Alex Vicente-Sola, Davide L. Manna, Paul Kirkland, Gaetano Di Caterina, and
Trevor Bihl.

</span>
<span class="ltx_bibblock">Keys to accurate feature extraction using residual spiking neural
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv</span>, abs/2111.05955, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Syed Ahmed Aamir, Yannik Stradmann, Paul Muller, Christian Pehle, Andreas
Hartel, Andreas Grubl, Johannes Schemmel, and Karlheinz Meier.

</span>
<span class="ltx_bibblock">An accelerated LIF neuronal network array for a large-scale
mixed-signal neuromorphic architecture.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Circuits and Systems I: Regular Papers</span>,
65(12):4299–4312, dec 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Alan Diamond, Thomas Nowotny, and Michael Schmuker.

</span>
<span class="ltx_bibblock">Comparing neuromorphic solutions in action: Implementing a
bio-inspired solution to a benchmark classification task on three
parallel-computing platforms.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Frontiers in Neuroscience</span>, 9, jan 2016.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ken E. Friedl, Aaron R. Voelker, Angelika Peer, and Chris Eliasmith.

</span>
<span class="ltx_bibblock">Human-inspired neurorobotic system for classifying surface textures
by touch.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">IEEE Robotics and Automation Letters</span>, 1(1):516–523, jan
2016.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Eric Hunsberger and Chris Eliasmith.

</span>
<span class="ltx_bibblock">Spiking deep networks with lif neurons.

</span>
<span class="ltx_bibblock">October 2015.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Göltz, L. Kriener, A. Baumbach, S. Billaudelle, O. Breitwieser, B. Cramer,
D. Dold, A. F. Kungl, W. Senn, J. Schemmel, K. Meier, and M. A. Petrovici.

</span>
<span class="ltx_bibblock">Fast and energy-efficient neuromorphic deep learning with first-spike
times.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, 3(9):823–835, sep 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Milad Mozafari, Saeed Reza Kheradpisheh, Timothee Masquelier, Abbas
Nowzari-Dalini, and Mohammad Ganjtabesh.

</span>
<span class="ltx_bibblock">First-spike-based visual categorization using reward-modulated
STDP.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>,
29(12):6178–6190, dec 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Evangelos Stromatias, Daniel Neil, Francesco Galluppi, Michael Pfeiffer,
Shih-Chii Liu, and Steve Furber.

</span>
<span class="ltx_bibblock">Scalable energy-efficient, low-latency implementations of trained
spiking deep belief networks on SpiNNaker.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2015 International Joint Conference on Neural Networks
(IJCNN)</span>. IEEE, jul 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Hesham Mostafa.

</span>
<span class="ltx_bibblock">Supervised learning based on temporal coding in spiking neural
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>,
29(7):3227–3235, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Soni Chaturvedi, AA Khurshid, and Meftah Boudjelal.

</span>
<span class="ltx_bibblock">Image segmentation using leaky integrate-and-fire model of spiking
neural network.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">International Journal of Wisdom Based Computing</span>, 2(1):21–28,
2012.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Chunming Jiang, Le Yang, and Yilei Zhang.

</span>
<span class="ltx_bibblock">A spiking neural network with spike-timing-dependent plasticity for
surface roughness analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">IEEE Sensors Journal</span>, 22(1):438–445, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Alberto Patino-Saucedo, Horacio Rostro-González, Teresa
Serrano-Gotarredona, and Bernabé Linares-Barranco.

</span>
<span class="ltx_bibblock">Event-driven implementation of deep spiking convolutional neural
networks for supervised classification using the spinnaker neuromorphic
platform.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Neural networks : the official journal of the International
Neural Network Society</span>, 121:319–328, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Tanguy Fardet, Mathieu Ballandras, Samuel Bottani, Stéphane Métens,
and Pascal Monceau.

</span>
<span class="ltx_bibblock">Understanding the generation of network bursts by adaptive
oscillatory neurons.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Frontiers in Neuroscience</span>, 12, feb 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Katayoon Taherkhani and Mahdi Aliyari Shoorehdeli.

</span>
<span class="ltx_bibblock">An artificial neural network based on izhikevich neuron model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">2017 Iranian Conference on Electrical Engineering (ICEE)</span>.
IEEE, may 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Soni Chaturvedi, Rutika N. Titre, and Neha Sondhiya.

</span>
<span class="ltx_bibblock">Review of handwritten pattern recognition of digits and special
characters using feed forward neural network and izhikevich neural model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">2014 International Conference on Electronic Systems, Signal
Processing and Computing Technologies</span>. IEEE, jan 2014.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Roberto A. Vazquez.

</span>
<span class="ltx_bibblock">Training spiking neural models using cuckoo search algorithm.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">2011 IEEE Congress of Evolutionary Computation (CEC)</span>.
IEEE, jun 2011.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Henry Markram, Maria Toledo-Rodriguez, Yun Wang, Anirudh Gupta, Gilad
Silberberg, and Caizhi Wu.

</span>
<span class="ltx_bibblock">Interneurons of the neocortical inhibitory system.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Nature Reviews Neuroscience</span>, 5(10):793–807, oct 2004.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Barry W. Connors and Michael J. Gutnick.

</span>
<span class="ltx_bibblock">Intrinsic firing patterns of diverse neocortical neurons.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Trends in Neurosciences</span>, 13(3):99–104, mar 1990.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Stephanie Dauth, Ben M. Maoz, Sean P. Sheehy, Matthew A. Hemphill, Tara Murty,
Mary Kate Macedonia, Angie M. Greer, Bogdan Budnik, and Kevin Kit Parker.

</span>
<span class="ltx_bibblock">Neurons derived from different brain regions are inherently different
in vitro: a novel multiregional brain-on-a-chip.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Journal of Neurophysiology</span>, 117(3):1320–1341, 2017.

</span>
<span class="ltx_bibblock">PMID: 28031399.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Garrick Orchard, Ajinkya Jayawant, Gregory K. Cohen, and Nitish Thakor.

</span>
<span class="ltx_bibblock">Converting static image datasets to spiking neuromorphic datasets
using saccades.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Frontiers in Neuroscience</span>, 9, nov 2015.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Arnon Amir, Brian Taba, David Berg, Timothy Melano, Jeffrey McKinstry, Carmelo
Di Nolfo, Tapan Nayak, Alexander Andreopoulos, Guillaume Garreau, Marcela
Mendoza, Jeff Kusnitz, Michael Debole, Steve Esser, Tobi Delbruck, Myron
Flickner, and Dharmendra Modha.

</span>
<span class="ltx_bibblock">A low power, fully event-based gesture recognition system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span>, pages 7388–7397, 2017.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Milad Mozafari, Mohammad Ganjtabesh, Abbas Nowzari-Dalini, and Timothée
Masquelier.

</span>
<span class="ltx_bibblock">Spyketorch: Efficient simulation of convolutional spiking neural
networks with at most one spike per neuron.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Frontiers in Neuroscience</span>, 13, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
L. Lapicque.

</span>
<span class="ltx_bibblock">Recherches quantitatives sur l’excitation electrique des nerfs
traitée comme une polarization.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Journal de Physiologie et Pathologie General</span>, 9:620–635, 1907.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. L. Hodgkin and A. F. Huxley.

</span>
<span class="ltx_bibblock">A quantitative description of membrane current and its application to
conduction and excitation in nerve.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">The Journal of Physiology</span>, 117(4):500–544, aug 1952.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Wulfram Gerstner and Werner M. Kistler.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Spiking Neuron Models</span>.

</span>
<span class="ltx_bibblock">Cambridge University Press, aug 2002.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Wulfram Gerstner, Raphael Ritz, and J Leo van Hemmen.

</span>
<span class="ltx_bibblock">A biologically motivated and analytically soluble model of collective
oscillations in the cortex.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Biological cybernetics</span>, 68(4):363–374, 1993.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Carl Van Vreeswijk and Haim Sompolinsky.

</span>
<span class="ltx_bibblock">Chaos in neuronal networks with balanced excitatory and inhibitory
activity.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Science</span>, 274(5293):1724–1726, 1996.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Mitsuo Kawato and Hiroaki Gomi.

</span>
<span class="ltx_bibblock">A computational model of four regions of the cerebellum based on
feedback-error learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Biological cybernetics</span>, 68(2):95–103, 1992.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
D Zipser, B Kehoe, G Littlewort, and J Fuster.

</span>
<span class="ltx_bibblock">A spiking network model of short-term active memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Journal of Neuroscience</span>, 13(8):3406–3420, 1993.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Wolfgang Maass.

</span>
<span class="ltx_bibblock">Lower bounds for the computational power of networks of spiking
neurons.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 8(1):1–40, 1996.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Wolfgang Maass.

</span>
<span class="ltx_bibblock">Networks of spiking neurons: The third generation of neural network
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Neural Networks</span>, 10(9):1659–1671, dec 1997.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Deep Learning</span>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.deeplearningbook.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.deeplearningbook.org</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Sagar Sharma, Simone Sharma, and Anidhya Athaiya.

</span>
<span class="ltx_bibblock">Activation functions in neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">towards data science</span>, 6(12):310–316, 2017.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Andrew L. Maas.

</span>
<span class="ltx_bibblock">Rectifier nonlinearities improve neural network acoustic models.

</span>
<span class="ltx_bibblock">2013.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Delving deep into rectifiers: Surpassing human-level performance on
imagenet classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">2015 IEEE International Conference on Computer Vision (ICCV)</span>,
pages 1026–1034, 2015.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Fast and accurate deep network learning by exponential linear units
(elus).

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">arXiv: Learning</span>, 2016.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Prajit Ramachandran, Barret Zoph, and Quoc V. Le.

</span>
<span class="ltx_bibblock">Searching for activation functions.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, abs/1710.05941, 2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Dabal Pedamonti.

</span>
<span class="ltx_bibblock">Comparison of non-linear activation functions for deep neural
networks on mnist classification task.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1804.02763</span>, 2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Steffen Eger, Paul Youssef, and Iryna Gurevych.

</span>
<span class="ltx_bibblock">Is it time to swish? comparing deep learning activation functions
across nlp tasks.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1901.02671</span>, 2019.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Bin Ding, Huimin Qian, and Jun Zhou.

</span>
<span class="ltx_bibblock">Activation functions and their characteristics in deep neural
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">2018 Chinese Control And Decision Conference (CCDC)</span>, pages
1836–1841, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Qinghe Zheng, Mingqiang Yang, Xinyu Tian, Xiaochen Wang, and Deqiang Wang.

</span>
<span class="ltx_bibblock">Rethinking the role of activation functions in deep convolutional
neural networks for image classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Engineering Letters</span>, 28(1), 2020.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Mohit Goyal, Rajan Goyal, P. Venkatappa Reddy, and Brejesh Lall.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Activation Functions</span>, pages 1–30.

</span>
<span class="ltx_bibblock">Springer International Publishing, Cham, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Ameya D. Jagtap, Kenji Kawaguchi, and George Em Karniadakis.

</span>
<span class="ltx_bibblock">Adaptive activation functions accelerate convergence in deep and
physics-informed neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Journal of Computational Physics</span>, 404:109136, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Alexander Sboev, Roman Rybka, Alexey Serenko, Danila Vlasov, Nikolay
Kudryashov, and Vyacheslav Demin.

</span>
<span class="ltx_bibblock">To the role of the choice of the neuron model in spiking network
learning on base of spike-timing-dependent plasticity.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Procedia Computer Science</span>, 123:432–439, 2018.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
E.M. Izhikevich.

</span>
<span class="ltx_bibblock">Which model to use for cortical spiking neurons?

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks</span>, 15(5):1063–1070, sep
2004.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Lyle Long and Guoliang Fang.

</span>
<span class="ltx_bibblock">A review of biologically plausible neuron models for spiking neural
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">AIAA Infotech@Aerospace 2010</span>. American Institute of
Aeronautics and Astronautics, apr 2010.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Adam Barton, Eva Volna, and Martin Kotyrba.

</span>
<span class="ltx_bibblock">The application perspective of izhikevich spiking neural model
– the initial experimental study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Recent Advances in Soft Computing</span>, pages 223–232. Springer
International Publishing, aug 2018.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Gautam Kumar, V. Aggarwal, N.v Thakor, Marc Schieber, and M.V. Kothare.

</span>
<span class="ltx_bibblock">Optimal parameter estimation of the izhikevich single neuron model
using experimental inter-spike interval (isi) data.

</span>
<span class="ltx_bibblock">pages 3586 – 3591, 08 2010.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Corinne Teeter, Ramakrishnan Iyer, Vilas Menon, Nathan Gouwens, David Feng, Jim
Berg, Aaron Szafer, Nicholas Cain, Hongkui Zeng, Michael Hawrylycz, Christof
Koch, and Stefan Mihalas.

</span>
<span class="ltx_bibblock">Generalized leaky integrate-and-fire models classify multiple neuron
types.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Nature Communications</span>, 9(1), feb 2018.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Renaud Jolivet, Alexander Rauch, Hans-rudolf Lüscher, and Wulfram Gerstner.

</span>
<span class="ltx_bibblock">Integrate-and-fire models with adaptation are good enough.

</span>
<span class="ltx_bibblock">In Y. Weiss, B. Schölkopf, and J. Platt, editors, <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">Advances
in Neural Information Processing Systems</span>, volume 18. MIT Press, 2005.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Beata J. Grzyb, Eris Chinellato, Grzegorz M. Wojcik, and Wieslaw A. Kaminski.

</span>
<span class="ltx_bibblock">Which model to use for the liquid state machine?

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">2009 International Joint Conference on Neural Networks</span>.
IEEE, jun 2009.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Eugene M. Izhikevich.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Dynamical Systems in Neuroscience</span>.

</span>
<span class="ltx_bibblock">MIT Press Ltd, January 2010.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Richard FitzHugh.

</span>
<span class="ltx_bibblock">Impulses and physiological states in theoretical models of nerve
membrane.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">Biophysical Journal</span>, 1(6):445–466, jul 1961.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
J. Nagumo, S. Arimoto, and S. Yoshizawa.

</span>
<span class="ltx_bibblock">An active pulse transmission line simulating nerve axon.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">Proceedings of the IRE</span>, 50(10):2061–2070, oct 1962.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
J. L. Hindmarsh and R. M. Rose.

</span>
<span class="ltx_bibblock">A model of neuronal bursting using three coupled first order
differential equations.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Proceedings of the Royal Society of London. Series B. Biological
Sciences</span>, 221(1222):87–102, mar 1984.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
C. Morris and H. Lecar.

</span>
<span class="ltx_bibblock">Voltage oscillations in the barnacle giant muscle fiber.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Biophysical Journal</span>, 35(1):193–213, jul 1981.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
A. N. Burkitt.

</span>
<span class="ltx_bibblock">A review of the integrate-and-fire neuron model: I. homogeneous
synaptic input.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Biological Cybernetics</span>, 95(1):1–19, apr 2006.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
W. Gerstner and R. Naud.

</span>
<span class="ltx_bibblock">How good are neuron models?

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">Science</span>, 326(5951):379–380, oct 2009.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Nicolas Fourcaud-Trocmé, David Hansel, Carl van Vreeswijk, and Nicolas
Brunel.

</span>
<span class="ltx_bibblock">How spike generation mechanisms determine the neuronal response to
fluctuating inputs.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">The Journal of Neuroscience</span>, 23(37):11628–11640, dec 2003.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
G. B. Ermentrout and N. Kopell.

</span>
<span class="ltx_bibblock">Parabolic bursting in an excitable system coupled with a slow
oscillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">SIAM Journal on Applied Mathematics</span>, 46(2):233–253, apr
1986.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Romain Brette and Wulfram Gerstner.

</span>
<span class="ltx_bibblock">Adaptive exponential integrate-and-fire model as an effective
description of neuronal activity.

</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">Journal of Neurophysiology</span>, 94(5):3637–3642, nov 2005.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
E.M. Izhikevich.

</span>
<span class="ltx_bibblock">Simple model of spiking neurons.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks</span>, 14(6):1569–1572, nov
2003.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Xiang Cheng, Yunzhe Hao, Jiaming Xu, and Bo Xu.

</span>
<span class="ltx_bibblock">Lisnn: Improving spiking neural networks with lateral interactions
for robust object recognition.

</span>
<span class="ltx_bibblock">In Christian Bessiere, editor, <span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">Proceedings of the Twenty-Ninth
International Joint Conference on Artificial Intelligence, IJCAI-20</span>, pages
1519–1525. International Joint Conferences on Artificial Intelligence
Organization, 7 2020.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Timothée Masquelier and Simon J Thorpe.

</span>
<span class="ltx_bibblock">Unsupervised learning of visual features through spike timing
dependent plasticity.

</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">PLoS computational biology</span>, 3(2):e31, 2007.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Paul Kirkland, Gaetano Di Caterina, John Soraghan, and George Matich.

</span>
<span class="ltx_bibblock">Spikeseg: Spiking segmentation via stdp saliency mapping.

</span>
<span class="ltx_bibblock">In <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">2020 International Joint Conference on Neural Networks
(IJCNN)</span>, pages 1–8, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Paul Kirkland, Davide L. Manna, Alex Vicente-Sola, and Gaetano Di Caterina.

</span>
<span class="ltx_bibblock">Unsupervised spiking instance segmentation on event data using
STDP.

</span>
<span class="ltx_bibblock"><span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">arXiv</span>, abs/2111.05283, 2021.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Aboozar Taherkhani, Ammar Belatreche, Yuhua Li, Georgina Cosma, Liam P.
Maguire, and T.M. McGinnity.

</span>
<span class="ltx_bibblock">A review of learning in biologically plausible spiking neural
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Neural Networks</span>, 122:253–272, feb 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Peter Diehl and Matthew Cook.

</span>
<span class="ltx_bibblock">Unsupervised learning of digit recognition using
spike-timing-dependent plasticity.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">Frontiers in Computational Neuroscience</span>, 9, 2015.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Laxmi R. Iyer and Arindam Basu.

</span>
<span class="ltx_bibblock">Unsupervised learning of event-based image recordings using
spike-timing-dependent plasticity.

</span>
<span class="ltx_bibblock">In <span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">2017 International Joint Conference on Neural Networks
(IJCNN)</span>, pages 1840–1846, 2017.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Stefan Falkner, Aaron Klein, and Frank Hutter.

</span>
<span class="ltx_bibblock">Bohb: Robust and efficient hyperparameter optimization at scale.

</span>
<span class="ltx_bibblock">In <span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">ICML</span>, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2207.04880" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2207.04881" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2207.04881">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2207.04881" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2207.04882" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Dec 22 21:50:40 2022 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
